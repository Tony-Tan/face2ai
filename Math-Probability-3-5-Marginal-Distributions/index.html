<!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=6.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=6.4.0"><link rel="mask-icon" href="/images/logo.png?v=6.4.0" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"6.4.0",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="Abstract: 本文承接上文，对于二维联合分布，如何求出二维变量中一个变量的一个分布，也就是标题所说的边缘分布；以及对独立随机变量的讨论。Keywords: Marginal p.f.,Marginal p.d.f.,Independent"><meta name="keywords" content="Marginal p.f.,边缘概率函数,Marginal p.d.f.,边缘密度函数,Independent,独立性"><meta property="og:type" content="article"><meta property="og:title" content="【概率论】3-5:边缘分布(Marginal Distribution)"><meta property="og:url" content="http://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions/index.html"><meta property="og:site_name" content="谭升的博客"><meta property="og:description" content="Abstract: 本文承接上文，对于二维联合分布，如何求出二维变量中一个变量的一个分布，也就是标题所说的边缘分布；以及对独立随机变量的讨论。Keywords: Marginal p.f.,Marginal p.d.f.,Independent"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-3-5-Marginal-Distributions/proof.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-3-5-Marginal-Distributions/proof.png"><meta property="og:updated_time" content="2018-09-20T04:53:18.217Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【概率论】3-5:边缘分布(Marginal Distribution)"><meta name="twitter:description" content="Abstract: 本文承接上文，对于二维联合分布，如何求出二维变量中一个变量的一个分布，也就是标题所说的边缘分布；以及对独立随机变量的讨论。Keywords: Marginal p.f.,Marginal p.d.f.,Independent"><meta name="twitter:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-3-5-Marginal-Distributions/proof.png"><link rel="canonical" href="http://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>【概率论】3-5:边缘分布(Marginal Distribution) | 谭升的博客</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105335860-3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-105335860-3")</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">谭升的博客</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Machine Learning & Computer Vision</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-首页"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-数学"><a href="/categories/Mathematic/" rel="section">数学</a></li><li class="menu-item menu-item-···-集合论"><a href="/categories/Mathematic/Set-Theory/" rel="section">··· 集合论</a></li><li class="menu-item menu-item-···-线性代数基础"><a href="/categories/Mathematic/Linear-Algebra/" rel="section">··· 线性代数基础</a></li><li class="menu-item menu-item-···-概率论基础"><a href="/categories/Mathematic/Probability/" rel="section">··· 概率论基础</a></li><li class="menu-item menu-item-···-数理统计学"><a href="/categories/Mathematic/Statistics/" rel="section">··· 数理统计学</a></li><li class="menu-item menu-item-···-数值分析"><a href="/categories/Mathematic/Numerical-Analysis/" rel="section">··· 数值分析</a></li><li class="menu-item menu-item-机器学习算法"><a href="/categories/Machine-Learning/" rel="section">机器学习算法</a></li><li class="menu-item menu-item-强化学习"><a href="/categories/Reinforcement-Learning/" rel="section">强化学习</a></li><li class="menu-item menu-item-深度学习算法"><a href="/categories/Deep-Learning/" rel="section">深度学习算法</a></li><li class="menu-item menu-item-数字图像处理"><a href="/categories/DIP/" rel="section">数字图像处理</a></li><li class="menu-item menu-item-30天自制操作系统"><a href="/categories/30天自制操作系统/" rel="section">30天自制操作系统</a></li><li class="menu-item menu-item-cuda"><a href="/categories/CUDA/" rel="section">CUDA</a></li><li class="menu-item menu-item-网络爬虫"><a href="/categories/Crawler/" rel="section">网络爬虫</a></li><li class="menu-item menu-item-乱七八糟"><a href="/categories/Other/" rel="section">乱七八糟</a></li></ul></nav><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/weixingongzhonghao.jpg" alt="wechat"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Tony"><meta itemprop="description" content="关注机器学习，深度学习，机器视觉，模式识别"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="谭升的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">【概率论】3-5:边缘分布(Marginal Distribution)</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-02-09 11:33:45" itemprop="dateCreated datePublished" datetime="2018-02-09T11:33:45+08:00">2018-02-09</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/" itemprop="url" rel="index"><span itemprop="name">Mathematic</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/Probability/" itemprop="url" rel="index"><span itemprop="name">Probability</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数： <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Abstract:</strong> 本文承接上文，对于二维联合分布，如何求出二维变量中一个变量的一个分布，也就是标题所说的边缘分布；以及对独立随机变量的讨论。<br><strong>Keywords:</strong> Marginal p.f.,Marginal p.d.f.,Independent</p><a id="more"></a><h2 id="开篇废话"><a href="#开篇废话" class="headerlink" title="开篇废话"></a>开篇废话</h2><p>今天这篇可能是农历新年前最后一篇关于数学的博客了，过年期间争取把CUDA系列的写出来，大家有兴趣的可以关注一下，过年本来是个休息的时间，但是说实话，现在真的很讨厌过年，尤其是那些关心你生活的所谓亲戚们，可能是变向找平衡，或者是炫耀，具体案例我不说，已经烂大街了，只是觉得有点恶心，人们在内心是相互攀比相互较量，表面还要装作一团和气，然后各种映射暗示你不如他的地方。<br>过年就应该是一家团聚，相互祝福，相互鼓励的。<br>真的想找个没人的地方看一春节书，改变不了就是试着逃避吧。<br>想要逃出生天，好好学习，可能还有机会。</p><h2 id="Marginal-Distribution"><a href="#Marginal-Distribution" class="headerlink" title="Marginal Distribution"></a>Marginal Distribution</h2><p>我们继续我们的概率论，我们已经经历了概率论的变化过程是：从试验到样本空间，样本空间到事件，事件到概率（复合事件的概率，包括条件事件，独立事件等等扩展情况），样本空间到随机变量，随机变量的离散概率、连续概率，描述随机变量概率的工具（p.f.,p.d.f.,c.d.f.），然后随机变量被扩展为二维（离散的，连续的，混合的），今天我们在二维联合分布的情况下，推出今天的主要讨论目标：Marginal Distribution(边缘分布)<br>上文我们曾有一个小伏笔，我们想知道联合的p.f.或者p.d.f.怎么通过每个变量的p.f.或者p.d.f.求出的；或者我们反过来，如何通过联合的p.f.或者p.d.f.来得到每个变量自己的（一维的）p.f.或者p.d.f.。<br>这就是我们要说的今天的边缘分布，适用于p.d.f.或者p.d.或者c.d.f.</p><h2 id="Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f"><a href="#Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f" class="headerlink" title="Deriving a Marginal p.f. or a Marginal p.d.f."></a>Deriving a Marginal p.f. or a Marginal p.d.f.</h2><h3 id="Discrete"><a href="#Discrete" class="headerlink" title="Discrete"></a>Discrete</h3><p>首先我们来从简单的二维联合分布来看，从有限的离散二维联合分布，举个🌰 ：<br>对于一个二维分布，上文说得到的扔骰子和丢硬币，下面我们的例子硬币和骰子都不是均匀的，所以产生的概率分布与原始例子不太一样：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Head</th><th>Tail</th><th style="text-align:center">$f_1(x)$</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">$\frac{2}{24}$</td><td>$\frac{2}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">$\frac{3}{24}$</td><td>$\frac{1}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">$\frac{2}{24}$</td><td>$\frac{2}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">$f_2(y)$</td><td style="text-align:center">$\frac{5}{12}$</td><td>$\frac{7}{12}$</td><td style="text-align:center">1</td></tr></tbody></table><p>陈希孺先生在书中说，简单的来说，边缘概率就是上面这个表的边缘，下面的一行，右边的一列所表现出来的分布，下面的一行，就是变量y，试验（丢硬币的）的边缘分布，对应的右侧一列对应的是随机变量x对应的试验是扔骰子。</p><blockquote><p>Definition Marginal c.d.f./p.f./p.d.f. Suppose that X and Y have a joint distribution.The c.d.f. of X derived by theorem 3.4.5. is called the marginal c.d.f. of X.Similarly,the p.f. or p.d.f. of X associated with the marginal c.d.f. of X is called the marginal p.f. or marginal p.d.f. of X</p></blockquote><p>写书的好处就是可以省略掉很多前面已经写了的东西，然后一个指针指过去就可以了，写博客也可以，就像这样<a href="">3-4</a>，但是我们还是重写一遍定理3.4.5：</p><p>Theorem Let $X$ and $Y$ have a joint c.d.f. $F$.The c.d.f. $F_1$ of just the single random variable $X$ can be derived from the joint c.d.f. $F$ as $F_1(x)=lim_{y\to \infty}F(x,y)$.Similarly,the c.d.f. $F_2$ of $Y$ equals $F_2(y)=lim_{x\to \infty}F(x,y)$ ,for $0&lt;y\leq \infty$</p><p>定义3.4.5告诉我们如何把一个联合c.d.f.拆分出来，通过把一个变量写成无穷大，来得到另一个变量的c.d.f.，这个过程就是一个边缘c.d.f.的过程，对于p.f.和p.d.f.同样的操作得到的将会是边缘p.f.或者边缘p.d.f.</p><p>那么我们怎么得到边缘p.f.或者边缘p.d.f呢？</p><blockquote><p>Theorem If $X$ and $Y$ have a discrete joint distribution for thich the joint p.f. is $f$,then the marginal p.f. $f_1$ of $X$ is<br>$$<br>f_1(x)=\sum_{\text{All } y}f(x,y).<br>$$<br>Similarly,the marginal p.f. $f_2$ of $Y$ is<br>$$<br>f_2(y)=\sum_{\text{All } x}f(x,y).<br>$$</p></blockquote><p>这个定理可以用来计算一个二维离散随机变量的联合分布如何计算出两个离散变量分别的离散分布，而书上给出的证明也过于感性化，作者通过一副和我们上一篇类似的图来说明<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-3-5-Marginal-Distributions/proof.png" alt=""></p><p>$f_1(x)$ 是在联合分布概率函数中，某一个变量不变（$x$） 而另一个变量取和的这种方式，来得到的边缘分布（x的一个一维分布概率函数）。如果从最初的关于概率的定义出发，我们也能得到类似的结论，二维随机变量对应的可以能是一个试验的二维结果，二维结果就对应了两个维度的可能性，而这个二维联合p.f.就是描述这个二维结果发生的概率的，当一个维度的可能性被消除（也就是二维变一维：$(x,y)\to x$）那么就应该把同一个 $x$ 下的所有不同的 $y$ 都加起来，因为在二维联合分布情况下 $(x_i,y_k)$ 和 $(x_i,y_l)$ 是不相关的（$k\neq l$）所以可以进行加法。</p><h3 id="Continuous"><a href="#Continuous" class="headerlink" title="Continuous"></a>Continuous</h3><p>接着我们看连续情况下的：</p><blockquote><p>Theorem If X and Y have a continuous joint distribution with joint p.d.f $f$ then the marginal p.d.f. f_1 of X is<br>$$<br>f_1(x)=\int_{-\infty}^{\infty}f(x,y)dy \text{ for }-\infty&lt;x&lt;\infty<br>$$<br>Similarly,the marginal p.d.f.f_2 of Y is<br>$$<br>f_2(y)=\int_{-\infty}^{\infty}f(x,y)dx \text{ for }-\infty&lt;y&lt;\infty<br>$$</p></blockquote><p>这个证明方法有点意思，用到了c.d.f.的定义和c.d.f.的边缘分布的定义，我们假设这个二维连续联合分布的p.d.f是$f(x,y)$ 那么根据c.d.f.的定义$F(x,y)$ 为下面的式子：<br>$$<br>F(x,y)=\int^{x}_{-\infty}\int^{y}_{-\infty}f(x,y)dydx<br>$$<br>没问题，当我们想得到x的边缘c.d.f.，我们根据定理，要把$y\to \infty$<br>$$<br>F(x)=\int^{x}_{-\infty}\int^{\infty}_{-\infty}f(x,y)dydx<br>$$<br>F(x)和$f(x)$ 是导数与反导数的关系，所以，F(x) 求导可以得到：<br>$$<br>f(x)=\frac{dF(x)}{dx}=\frac{d\int^{x}_{-\infty}\int^{\infty}_{-\infty}f(x,y)dydx}{dx}\\<br>\text{set :}\int^{x}_{-\infty}[\int^{\infty}_{-\infty}f(x,y)dy]dx=\int^{x}_{-\infty}g(x)dx\\<br>\text{so }f(x)=g(x)=\int^{\infty}_{-\infty}f(x,y)dy<br>$$<br>Q.E.D</p><p>证明过程用到了单变量c.d.f.和p.d.f.之间的关系，上面提到的定理3.4.5（莫名其妙的编号来自原书），以及微积分基本定理，这个证明过程如上所述，简单粗暴（与书本给出的证明不太一样，如有问题请及时指出，谢谢）。</p><p>有了上面这些个公理，使用过程多半就变成了春计算，公理背后的逻辑就是上面我们的两个证明，一个图解，一个分析，虽然不太喜欢做计算，但是我们还是写个例子吧：<br>假设一个二维联合分布满足：<br>$$<br>f(x,y)=<br>\begin{cases}<br>\frac{21}{4}x^2y&amp;\text{for }x^2\leq y\leq 1\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$<br>求 $x$ 的边缘p.d.f.<br>$$<br>f_1(x)=\int^{\infty}_{-\infty}f(x,y)dy=\int^{1}_{x^2}\frac{21}{4}x^2ydy=(\frac{21}{8})x^2(1-x^4)<br>$$</p><h2 id="Mixed"><a href="#Mixed" class="headerlink" title="Mixed"></a>Mixed</h2><blockquote><p>Theorem Let f be the joint p.f./p.d.f. of X and Y,with X discrete and Y continuous.Then the marginal p.f. of X is :<br>$$<br>f_1(x)=Pr(X=x)=\int^{\infty}_{-\infty}f(x,y)dy \quad\text{for all }x<br>$$<br>and the marginal p.d.f. of Y is:<br>$$<br>f_2(y)=\sum_{x}f(x,y) \text{ for }-\infty&lt;y&lt;\infty<br>$$</p></blockquote><p>证明就是前两个的集合版本。例子也不再废话了，也是上面两个例子的结合，我们要进入下面这个比较重要的主题了，关于随机变量的独立性。</p><h2 id="Independent-Random-Variables"><a href="#Independent-Random-Variables" class="headerlink" title="Independent Random Variables"></a>Independent Random Variables</h2><p>我们前面研究过事件的独立性，事件独立不是不相关，而是其概率满足一定关系，我们称之为独立，也就是事件发生与否不会影响另一个事件，我们称之为相互独立，而我们通过随机变量把样本空间（也包括事件）过渡到实数，那么这些实数之间的概率相互独立是怎么回事呢？<br>对于离散随机变量，其独立性和事件的独立性非常相似：</p><p>$$<br>Pr((x,y))=Pr(x)Pr(y)<br>$$</p><p>但是对于连续变量，这个就有问题了，因为连续变量的单一位置的概率是0，<a href=""></a>中已经做了明确的介绍，所以我们要有一片区域代替一个点。<br>先来看一个总体的定义：</p><blockquote><p>Definition Independent Random Variables.It is said that two random variables $X$ and $Y$ are independent if,for every two sets $A$ and $B$ of real numbers such that ${x\in A}$ and ${Y\in B }$ are events,<br>$$<br>Pr(X\in A \text{ and } Y \in B)=Pr(X\in A)Pr(Y\in B)<br>$$</p></blockquote><p>从事件的角度去看这个定义很明确了我们假设事件 $E={X\in A}$ 事件 $F={Y\in B}$ 这两个事件独立的条件是当且仅当：<br>$$<br>Pr(E\cap F)=Pr(E)Pr(F)<br>$$</p><p>上面的定义并没有规定A和B的选择方法，那么我们可以规定如下的规则：<br>$$<br>Pr(X\in{X&lt;x})\\<br>Pr(Y\in{Y&lt;y})\\<br>\text{so we have:}\\<br>Pr(X\leq x\text{ and }Y\leq y)=Pr(X\leq x)Pr(Y\leq y)<br>$$</p><p>哈哈哈，看出来上面藏了个谁了么？没有？仔细看？还没有？再仔细看。</p><h3 id="判定独立方法-1"><a href="#判定独立方法-1" class="headerlink" title="判定独立方法 1"></a>判定独立方法 1</h3><blockquote><p>Theorem Let the joint c.d.f. of $X$ and $Y$ be $F$ let the marginal c.d.f. of $X$ be $F_1$ and let the marginal c.d.f. of $Y$ be $F_2$ Then $X$ and $Y$ are independent if and only if ,for all real numbers $x$ and $y$ ,<br>$F(x,y)=F_1(x)F_2(y)$</p></blockquote><p>怎么样，加上这个定理是不是明显一点了呢？<br>于是我们得到了一个确定随机变量是否独立的方法，随机变量独立的充分必要条件就是其c.d.f.满足乘法关系，怎么来的？随机变量独立的定义在上面规定的。</p><h3 id="判定独立方法-2"><a href="#判定独立方法-2" class="headerlink" title="判定独立方法 2"></a>判定独立方法 2</h3><p>上面的定理很简单，不需要解读，我们继续看下面的定理通过joint p.d.f., joint p.f. 或者是joint p.f./p.d.f. 确定随机变量独立：</p><blockquote><p>Theorem Suppose that $X$ and $Y$ are random varibales that have a joint p.f.,p.d.f. or p.f./p.d.f. $f$ ,Then $X$ and $Y$ will be independent if and only if $f$ can be represented in the following form for $-\infty&lt;x&lt;\infty$ and $-\infty&lt;y&lt;\infty$ :<br>$$<br>f(x,y)=h_1(x)h_2(y)<br>$$</p></blockquote><p>这个定理给出了用pdf或者pf或者混合pf和pdf确定随机变量独立的方法，我们这里证明最复杂的情况，一个是离散的随机变量x，一个是连续的随机变量y，证明过程分为两部分，</p><hr><ul><li>“if” part:<br>$$<br>\text{ hold: } f(x,y)=h_1(x)h_2(y) \\<br>\text{marginal p.d.f. of }x\text{ : }f_1(x)=\int^{\infty}_{-\infty}h_1(x)h_2(y)dy=c_1h_1(x)<br>$$<br>$c_1$ 是一个非负函数积分的结果，所以我们保证其是非负数，同时我们确定其有限，并且不是0，那么我们就能得到：<br>$$<br>h_1(x)=\frac{f_1(x)}{c_1}<br>$$<br>与此相似，我们用求和的方法求离散的边缘分布：<br>$$<br>f_2(y)=\sum_{x}f(x,y)=\sum_{\text{All }x}h_1(x)h_2(y)=h_2(y)\sum_{x}\frac{1}{c_1}f_1(x)=\frac{1}{c}h_2(y)<br>$$</li></ul><p>我们分别求出了两个随机变量的概率密度函数和概率函数（这两个函数具有任一性，也就是可以代表整个pdf或者pf族），所以我们可以得到结论：<br>$$<br>f(x,y)=\frac{f_1(x)}{c_1} c_1 f_2(y)=f_1(x)f_2(y)<br>$$</p><p>结合我们关于随机变量的定义(mixed 版本)：<br>$$<br>Pr(X\in A \text{ and } Y \in B)=\sum_{X \in A}\int_Bf(x,y)dy\\<br>=\int_B\sum_{X\in A}f_1(x)f_2(y)dy=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy<br>$$<br>所以根据定义，随机变量独立！</p><hr><ul><li>“only if” part:<br>we assume that X and Y are independent:<br>$$<br>Pr(X\in A \text{ and } Y \in B)\\<br>=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy\\<br>=\int_B\sum_{X\in A}f_1(x)f_2(y)dy<br>$$<br>经过上面的分解，我们就能得到两个随机变量的概率<br>$$<br>Pr(A)=h_1(x)=\sum_{X\in A}f_1(x)\\<br>Pr(B)=h_2(y)=\int_Bf_2(y)dy<br>$$<br>这部分证明过程用到了上一篇混合随机变量的联合概率密度函数( $Pr(X\in A \text{ and } Y \in B)=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy$ ) 然后通过微积分的基本过程得到了结论</li></ul><p>Q.E.D</p><hr><p>所以我们在平时思考的时候，当我们考虑两个随机变量是否独立的时候，只要思考当一个概率密度函数（概率函数）从未知变成已知的时候时，另一个是否受到影响，反之亦然。</p><p>举个例子：<br>假设两个连续变量满足如下分布<br>$$<br>f(x,y)=<br>\begin{cases}<br>kx^2y^2&amp;\text{for }x^2+y^2\leq 1\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$<br>X,Y是否独立。<br>明显这个是不独立的，为啥，我们发现，$f_1(0.9)\neq 0$ 而 $f_2(0.9)\neq 0$ 但是<br>$f_1(0.9)f_2(0.9)=0$<br>所以我们可以确定其并不独立。</p><p>我们看出这个例子的定义域是个圆心在原点，半径为1的圆，那么这个定义域和独立与否是否有关系呢？<br>于是我们引出下面的定理：</p><h3 id="判定独立方法-3"><a href="#判定独立方法-3" class="headerlink" title="判定独立方法 3"></a>判定独立方法 3</h3><blockquote><p>Theorem Let $X$ and $Y$ have a continuous joint distribution .Suppose that ${(x,y):f(x,y)&gt;0}$ is a rectangular region $R$ (possibly unbounded) with sides (if any) parallel to the coordinate axes.Then X and Y are independent if and only if $f(x,y)=h_1(x)h_2(y)$ holds for all $(x,y)\in \Re^2$</p></blockquote><p>这个定理对于上面例题是个很好的总结，当随机变量范围不是一个边和数轴平行的矩形时（有无边界无所谓，也就是开区间还是闭区间无所谓）没有可能独立，肯定相关，只有当其实矩形的时候，才有可能是独立的，是矩形，同时满足上面的给出的判断定理，就能确定是否独立了。<br>这个可以看做一个判定方法，也可以说是2的一个扩展</p><h3 id="判定独立方法-4"><a href="#判定独立方法-4" class="headerlink" title="判定独立方法 4"></a>判定独立方法 4</h3><p>对于形式上就是分离的函数，其随机变量独立：<br>$$<br>f(x,y)=e^xy\quad \text{ for } -\infty&lt;x&lt;0 \text{ and }0&lt;y&lt;1<br>$$<br>这个x和y的函数可以一眼就分离开了，同时定义域是矩形，而且积分是1（我自己编的例子，有问题请留言）<br>从定义上证明也很好证明，我们的定义是：<br>$$<br>Pr(X\in A \text{ and } Y \in B)=Pr(X\in A)Pr(Y\in B)<br>$$</p><p>那么我们就把事件A设置成 $Pr(A)=e^x$ 事件B设置成 $Pr(B)=y$ 这就明显了，<br>$$<br>Pr(X\in {X&lt;e^x} \text{ and } Y \in {Y&lt;y})=e^xy<br>$$</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文知识点主要在随机变量的独立上，边缘概率比较直观，后面的条件概率和边缘概率有点相似，但是更复杂更有用一些，我们年后继续，祝大家新年快乐！</p><h2 id="待续。。。。。"><a href="#待续。。。。。" class="headerlink" title="待续。。。。。"></a>待续。。。。。</h2><p>title: 【概率论】3-5:边缘分布(Marginal Distribution)<br>categories:</p><ul><li>Mathematic</li><li>Probability<br>keywords:</li><li>Marginal p.f.</li><li>边缘概率函数</li><li>Marginal p.d.f.</li><li>边缘密度函数</li><li>Independent</li><li>独立性<br>toc: true<br>date: 2018-02-09 11:33:45</li></ul><hr><p><strong>Abstract:</strong> 本文承接上文，对于二维联合分布，如何求出二维变量中一个变量的一个分布，也就是标题所说的边缘分布；以及对独立随机变量的讨论。<br><strong>Keywords:</strong> Marginal p.f.,Marginal p.d.f.,Independent</p><!--more--><h2 id="开篇废话-1"><a href="#开篇废话-1" class="headerlink" title="开篇废话"></a>开篇废话</h2><p>今天这篇可能是农历新年前最后一篇关于数学的博客了，过年期间争取把CUDA系列的写出来，大家有兴趣的可以关注一下，过年本来是个休息的时间，但是说实话，现在真的很讨厌过年，尤其是那些关心你生活的所谓亲戚们，可能是变向找平衡，或者是炫耀，具体案例我不说，已经烂大街了，只是觉得有点恶心，人们在内心是相互攀比相互较量，表面还要装作一团和气，然后各种映射暗示你不如他的地方。<br>过年就应该是一家团聚，相互祝福，相互鼓励的。<br>真的想找个没人的地方看一春节书，改变不了就是试着逃避吧。<br>想要逃出生天，好好学习，可能还有机会。</p><h2 id="Marginal-Distribution-1"><a href="#Marginal-Distribution-1" class="headerlink" title="Marginal Distribution"></a>Marginal Distribution</h2><p>我们继续我们的概率论，我们已经经历了概率论的变化过程是：从试验到样本空间，样本空间到事件，事件到概率（复合事件的概率，包括条件事件，独立事件等等扩展情况），样本空间到随机变量，随机变量的离散概率、连续概率，描述随机变量概率的工具（p.f.,p.d.f.,c.d.f.），然后随机变量被扩展为二维（离散的，连续的，混合的），今天我们在二维联合分布的情况下，推出今天的主要讨论目标：Marginal Distribution(边缘分布)<br>上文我们曾有一个小伏笔，我们想知道联合的p.f.或者p.d.f.怎么通过每个变量的p.f.或者p.d.f.求出的；或者我们反过来，如何通过联合的p.f.或者p.d.f.来得到每个变量自己的（一维的）p.f.或者p.d.f.。<br>这就是我们要说的今天的边缘分布，适用于p.d.f.或者p.d.或者c.d.f.</p><h2 id="Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f-1"><a href="#Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f-1" class="headerlink" title="Deriving a Marginal p.f. or a Marginal p.d.f."></a>Deriving a Marginal p.f. or a Marginal p.d.f.</h2><h3 id="Discrete-1"><a href="#Discrete-1" class="headerlink" title="Discrete"></a>Discrete</h3><p>首先我们来从简单的二维联合分布来看，从有限的离散二维联合分布，举个🌰 ：<br>对于一个二维分布，上文说得到的扔骰子和丢硬币，下面我们的例子硬币和骰子都不是均匀的，所以产生的概率分布与原始例子不太一样：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Head</th><th>Tail</th><th style="text-align:center">$f_1(x)$</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">$\frac{2}{24}$</td><td>$\frac{2}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">$\frac{3}{24}$</td><td>$\frac{1}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">$\frac{1}{24}$</td><td>$\frac{3}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">$\frac{2}{24}$</td><td>$\frac{2}{24}$</td><td style="text-align:center">$\frac{1}{6}$</td></tr><tr><td style="text-align:center">$f_2(y)$</td><td style="text-align:center">$\frac{5}{12}$</td><td>$\frac{7}{12}$</td><td style="text-align:center">1</td></tr></tbody></table><p>陈希孺先生在书中说，简单的来说，边缘概率就是上面这个表的边缘，下面的一行，右边的一列所表现出来的分布，下面的一行，就是变量y，试验（丢硬币的）的边缘分布，对应的右侧一列对应的是随机变量x对应的试验是扔骰子。</p><blockquote><p>Definition Marginal c.d.f./p.f./p.d.f. Suppose that X and Y have a joint distribution.The c.d.f. of X derived by theorem 3.4.5. is called the marginal c.d.f. of X.Similarly,the p.f. or p.d.f. of X associated with the marginal c.d.f. of X is called the marginal p.f. or marginal p.d.f. of X</p></blockquote><p>写书的好处就是可以省略掉很多前面已经写了的东西，然后一个指针指过去就可以了，写博客也可以，就像这样<a href="">3-4</a>，但是我们还是重写一遍定理3.4.5：</p><p>Theorem Let $X$ and $Y$ have a joint c.d.f. $F$.The c.d.f. $F_1$ of just the single random variable $X$ can be derived from the joint c.d.f. $F$ as $F_1(x)=lim_{y\to \infty}F(x,y)$.Similarly,the c.d.f. $F_2$ of $Y$ equals $F_2(y)=lim_{x\to \infty}F(x,y)$ ,for $0&lt;y\leq \infty$</p><p>定义3.4.5告诉我们如何把一个联合c.d.f.拆分出来，通过把一个变量写成无穷大，来得到另一个变量的c.d.f.，这个过程就是一个边缘c.d.f.的过程，对于p.f.和p.d.f.同样的操作得到的将会是边缘p.f.或者边缘p.d.f.</p><p>那么我们怎么得到边缘p.f.或者边缘p.d.f呢？</p><blockquote><p>Theorem If $X$ and $Y$ have a discrete joint distribution for thich the joint p.f. is $f$,then the marginal p.f. $f_1$ of $X$ is<br>$$<br>f_1(x)=\sum_{\text{All } y}f(x,y).<br>$$<br>Similarly,the marginal p.f. $f_2$ of $Y$ is<br>$$<br>f_2(y)=\sum_{\text{All } x}f(x,y).<br>$$</p></blockquote><p>这个定理可以用来计算一个二维离散随机变量的联合分布如何计算出两个离散变量分别的离散分布，而书上给出的证明也过于感性化，作者通过一副和我们上一篇类似的图来说明<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-3-5-Marginal-Distributions/proof.png" alt=""></p><p>$f_1(x)$ 是在联合分布概率函数中，某一个变量不变（$x$） 而另一个变量取和的这种方式，来得到的边缘分布（x的一个一维分布概率函数）。如果从最初的关于概率的定义出发，我们也能得到类似的结论，二维随机变量对应的可以能是一个试验的二维结果，二维结果就对应了两个维度的可能性，而这个二维联合p.f.就是描述这个二维结果发生的概率的，当一个维度的可能性被消除（也就是二维变一维：$(x,y)\to x$）那么就应该把同一个 $x$ 下的所有不同的 $y$ 都加起来，因为在二维联合分布情况下 $(x_i,y_k)$ 和 $(x_i,y_l)$ 是不相关的（$k\neq l$）所以可以进行加法。</p><h3 id="Continuous-1"><a href="#Continuous-1" class="headerlink" title="Continuous"></a>Continuous</h3><p>接着我们看连续情况下的：</p><blockquote><p>Theorem If X and Y have a continuous joint distribution with joint p.d.f $f$ then the marginal p.d.f. f_1 of X is<br>$$<br>f_1(x)=\int_{-\infty}^{\infty}f(x,y)dy \text{ for }-\infty&lt;x&lt;\infty<br>$$<br>Similarly,the marginal p.d.f.f_2 of Y is<br>$$<br>f_2(y)=\int_{-\infty}^{\infty}f(x,y)dx \text{ for }-\infty&lt;y&lt;\infty<br>$$</p></blockquote><p>这个证明方法有点意思，用到了c.d.f.的定义和c.d.f.的边缘分布的定义，我们假设这个二维连续联合分布的p.d.f是$f(x,y)$ 那么根据c.d.f.的定义$F(x,y)$ 为下面的式子：<br>$$<br>F(x,y)=\int^{x}_{-\infty}\int^{y}_{-\infty}f(x,y)dydx<br>$$<br>没问题，当我们想得到x的边缘c.d.f.，我们根据定理，要把$y\to \infty$<br>$$<br>F(x)=\int^{x}_{-\infty}\int^{\infty}_{-\infty}f(x,y)dydx<br>$$<br>F(x)和$f(x)$ 是导数与反导数的关系，所以，F(x) 求导可以得到：<br>$$<br>f(x)=\frac{dF(x)}{dx}=\frac{d\int^{x}_{-\infty}\int^{\infty}_{-\infty}f(x,y)dydx}{dx}\\<br>\text{set :}\int^{x}_{-\infty}[\int^{\infty}_{-\infty}f(x,y)dy]dx=\int^{x}_{-\infty}g(x)dx\\<br>\text{so }f(x)=g(x)=\int^{\infty}_{-\infty}f(x,y)dy<br>$$<br>Q.E.D</p><p>证明过程用到了单变量c.d.f.和p.d.f.之间的关系，上面提到的定理3.4.5（莫名其妙的编号来自原书），以及微积分基本定理，这个证明过程如上所述，简单粗暴（与书本给出的证明不太一样，如有问题请及时指出，谢谢）。</p><p>有了上面这些个公理，使用过程多半就变成了春计算，公理背后的逻辑就是上面我们的两个证明，一个图解，一个分析，虽然不太喜欢做计算，但是我们还是写个例子吧：<br>假设一个二维联合分布满足：<br>$$<br>f(x,y)=<br>\begin{cases}<br>\frac{21}{4}x^2y&amp;\text{for }x^2\leq y\leq 1\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$<br>求 $x$ 的边缘p.d.f.<br>$$<br>f_1(x)=\int^{\infty}_{-\infty}f(x,y)dy=\int^{1}_{x^2}\frac{21}{4}x^2ydy=(\frac{21}{8})x^2(1-x^4)<br>$$</p><h2 id="Mixed-1"><a href="#Mixed-1" class="headerlink" title="Mixed"></a>Mixed</h2><blockquote><p>Theorem Let f be the joint p.f./p.d.f. of X and Y,with X discrete and Y continuous.Then the marginal p.f. of X is :<br>$$<br>f_1(x)=Pr(X=x)=\int^{\infty}_{-\infty}f(x,y)dy \quad\text{for all }x<br>$$<br>and the marginal p.d.f. of Y is:<br>$$<br>f_2(y)=\sum_{x}f(x,y) \text{ for }-\infty&lt;y&lt;\infty<br>$$</p></blockquote><p>证明就是前两个的集合版本。例子也不再废话了，也是上面两个例子的结合，我们要进入下面这个比较重要的主题了，关于随机变量的独立性。</p><h2 id="Independent-Random-Variables-1"><a href="#Independent-Random-Variables-1" class="headerlink" title="Independent Random Variables"></a>Independent Random Variables</h2><p>我们前面研究过事件的独立性，事件独立不是不相关，而是其概率满足一定关系，我们称之为独立，也就是事件发生与否不会影响另一个事件，我们称之为相互独立，而我们通过随机变量把样本空间（也包括事件）过渡到实数，那么这些实数之间的概率相互独立是怎么回事呢？<br>对于离散随机变量，其独立性和事件的独立性非常相似：</p><p>$$<br>Pr((x,y))=Pr(x)Pr(y)<br>$$</p><p>但是对于连续变量，这个就有问题了，因为连续变量的单一位置的概率是0，<a href=""></a>中已经做了明确的介绍，所以我们要有一片区域代替一个点。<br>先来看一个总体的定义：</p><blockquote><p>Definition Independent Random Variables.It is said that two random variables $X$ and $Y$ are independent if,for every two sets $A$ and $B$ of real numbers such that ${x\in A}$ and ${Y\in B }$ are events,<br>$$<br>Pr(X\in A \text{ and } Y \in B)=Pr(X\in A)Pr(Y\in B)<br>$$</p></blockquote><p>从事件的角度去看这个定义很明确了我们假设事件 $E={X\in A}$ 事件 $F={Y\in B}$ 这两个事件独立的条件是当且仅当：<br>$$<br>Pr(E\cap F)=Pr(E)Pr(F)<br>$$</p><p>上面的定义并没有规定A和B的选择方法，那么我们可以规定如下的规则：<br>$$<br>Pr(X\in{X&lt;x})\\<br>Pr(Y\in{Y&lt;y})\\<br>\text{so we have:}\\<br>Pr(X\leq x\text{ and }Y\leq y)=Pr(X\leq x)Pr(Y\leq y)<br>$$</p><p>哈哈哈，看出来上面藏了个谁了么？没有？仔细看？还没有？再仔细看。</p><h3 id="判定独立方法-1-1"><a href="#判定独立方法-1-1" class="headerlink" title="判定独立方法 1"></a>判定独立方法 1</h3><blockquote><p>Theorem Let the joint c.d.f. of $X$ and $Y$ be $F$ let the marginal c.d.f. of $X$ be $F_1$ and let the marginal c.d.f. of $Y$ be $F_2$ Then $X$ and $Y$ are independent if and only if ,for all real numbers $x$ and $y$ ,<br>$F(x,y)=F_1(x)F_2(y)$</p></blockquote><p>怎么样，加上这个定理是不是明显一点了呢？<br>于是我们得到了一个确定随机变量是否独立的方法，随机变量独立的充分必要条件就是其c.d.f.满足乘法关系，怎么来的？随机变量独立的定义在上面规定的。</p><h3 id="判定独立方法-2-1"><a href="#判定独立方法-2-1" class="headerlink" title="判定独立方法 2"></a>判定独立方法 2</h3><p>上面的定理很简单，不需要解读，我们继续看下面的定理通过joint p.d.f., joint p.f. 或者是joint p.f./p.d.f. 确定随机变量独立：</p><blockquote><p>Theorem Suppose that $X$ and $Y$ are random varibales that have a joint p.f.,p.d.f. or p.f./p.d.f. $f$ ,Then $X$ and $Y$ will be independent if and only if $f$ can be represented in the following form for $-\infty&lt;x&lt;\infty$ and $-\infty&lt;y&lt;\infty$ :<br>$$<br>f(x,y)=h_1(x)h_2(y)<br>$$</p></blockquote><p>这个定理给出了用pdf或者pf或者混合pf和pdf确定随机变量独立的方法，我们这里证明最复杂的情况，一个是离散的随机变量x，一个是连续的随机变量y，证明过程分为两部分，</p><hr><ul><li>“if” part:<br>$$<br>\text{ hold: } f(x,y)=h_1(x)h_2(y) \\<br>\text{marginal p.d.f. of }x\text{ : }f_1(x)=\int^{\infty}_{-\infty}h_1(x)h_2(y)dy=c_1h_1(x)<br>$$<br>$c_1$ 是一个非负函数积分的结果，所以我们保证其是非负数，同时我们确定其有限，并且不是0，那么我们就能得到：<br>$$<br>h_1(x)=\frac{f_1(x)}{c_1}<br>$$<br>与此相似，我们用求和的方法求离散的边缘分布：<br>$$<br>f_2(y)=\sum_{x}f(x,y)=\sum_{\text{All }x}h_1(x)h_2(y)=h_2(y)\sum_{x}\frac{1}{c_1}f_1(x)=\frac{1}{c}h_2(y)<br>$$</li></ul><p>我们分别求出了两个随机变量的概率密度函数和概率函数（这两个函数具有任一性，也就是可以代表整个pdf或者pf族），所以我们可以得到结论：<br>$$<br>f(x,y)=\frac{f_1(x)}{c_1} c_1 f_2(y)=f_1(x)f_2(y)<br>$$</p><p>结合我们关于随机变量的定义(mixed 版本)：<br>$$<br>Pr(X\in A \text{ and } Y \in B)=\sum_{X \in A}\int_Bf(x,y)dy\\<br>=\int_B\sum_{X\in A}f_1(x)f_2(y)dy=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy<br>$$<br>所以根据定义，随机变量独立！</p><hr><ul><li>“only if” part:<br>we assume that X and Y are independent:<br>$$<br>Pr(X\in A \text{ and } Y \in B)\\<br>=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy\\<br>=\int_B\sum_{X\in A}f_1(x)f_2(y)dy<br>$$<br>经过上面的分解，我们就能得到两个随机变量的概率<br>$$<br>Pr(A)=h_1(x)=\sum_{X\in A}f_1(x)\\<br>Pr(B)=h_2(y)=\int_Bf_2(y)dy<br>$$<br>这部分证明过程用到了上一篇混合随机变量的联合概率密度函数( $Pr(X\in A \text{ and } Y \in B)=\sum_{X\in A}f_1(x)\int_Bf_2(y)dy$ ) 然后通过微积分的基本过程得到了结论</li></ul><p>Q.E.D</p><hr><p>所以我们在平时思考的时候，当我们考虑两个随机变量是否独立的时候，只要思考当一个概率密度函数（概率函数）从未知变成已知的时候时，另一个是否受到影响，反之亦然。</p><p>举个例子：<br>假设两个连续变量满足如下分布<br>$$<br>f(x,y)=<br>\begin{cases}<br>kx^2y^2&amp;\text{for }x^2+y^2\leq 1\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$<br>X,Y是否独立。<br>明显这个是不独立的，为啥，我们发现，$f_1(0.9)\neq 0$ 而 $f_2(0.9)\neq 0$ 但是<br>$f_1(0.9)f_2(0.9)=0$<br>所以我们可以确定其并不独立。</p><p>我们看出这个例子的定义域是个圆心在原点，半径为1的圆，那么这个定义域和独立与否是否有关系呢？<br>于是我们引出下面的定理：</p><h3 id="判定独立方法-3-1"><a href="#判定独立方法-3-1" class="headerlink" title="判定独立方法 3"></a>判定独立方法 3</h3><blockquote><p>Theorem Let $X$ and $Y$ have a continuous joint distribution .Suppose that ${(x,y):f(x,y)&gt;0}$ is a rectangular region $R$ (possibly unbounded) with sides (if any) parallel to the coordinate axes.Then X and Y are independent if and only if $f(x,y)=h_1(x)h_2(y)$ holds for all $(x,y)\in \Re^2$</p></blockquote><p>这个定理对于上面例题是个很好的总结，当随机变量范围不是一个边和数轴平行的矩形时（有无边界无所谓，也就是开区间还是闭区间无所谓）没有可能独立，肯定相关，只有当其实矩形的时候，才有可能是独立的，是矩形，同时满足上面的给出的判断定理，就能确定是否独立了。<br>这个可以看做一个判定方法，也可以说是2的一个扩展</p><h3 id="判定独立方法-4-1"><a href="#判定独立方法-4-1" class="headerlink" title="判定独立方法 4"></a>判定独立方法 4</h3><p>对于形式上就是分离的函数，其随机变量独立：<br>$$<br>f(x,y)=e^xy\quad \text{ for } -\infty&lt;x&lt;0 \text{ and }0&lt;y&lt;1<br>$$<br>这个x和y的函数可以一眼就分离开了，同时定义域是矩形，而且积分是1（我自己编的例子，有问题请留言）<br>从定义上证明也很好证明，我们的定义是：<br>$$<br>Pr(X\in A \text{ and } Y \in B)=Pr(X\in A)Pr(Y\in B)<br>$$</p><p>那么我们就把事件A设置成 $Pr(A)=e^x$ 事件B设置成 $Pr(B)=y$ 这就明显了，<br>$$<br>Pr(X\in {X&lt;e^x} \text{ and } Y \in {Y&lt;y})=e^xy<br>$$</p><h2 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文知识点主要在随机变量的独立上，边缘概率比较直观，后面的条件概率和边缘概率有点相似，但是更复杂更有用一些，我们年后继续，祝大家新年快乐！<br>待续。。。。。<br>原文地址1：<a href="https://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions">https://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions</a>转载请标明出处<br>原文地址2：<a href="https://www.tony4ai.com/Math-Probability-3-5-Marginal-Distributions" target="_blank" rel="noopener">https://www.tony4ai.com/Math-Probability-3-5-Marginal-Distributions</a>转载请标明出处</p></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>可怜可怜我吧</div><button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/weixin.png" alt="Tony 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"><img id="alipay_qr" src="/images/alipay.png" alt="Tony 支付宝"><p>支付宝</p></div></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>Tony</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions/" title="【概率论】3-5:边缘分布(Marginal Distribution)">http://www.face2ai.com/Math-Probability-3-5-Marginal-Distributions/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Math-Probability-3-4-Bivariate-Distribution/" rel="next" title="【概率论】3-4:二维分布(Bivariate Distribution)"><i class="fa fa-chevron-left"></i> 【概率论】3-4:二维分布(Bivariate Distribution)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/CUDA-F-0-0-Tencent-GPU-Cloud/" rel="prev" title="【CUDA 基础】0.0 腾讯云CUDA环境搭建">【CUDA 基础】0.0 腾讯云CUDA环境搭建 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Tony"><p class="site-author-name" itemprop="name">Tony</p><p class="site-description motion-element" itemprop="description">关注机器学习，深度学习，机器视觉，模式识别</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">259</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">17</span> <span class="site-state-item-name">分类</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tony-tan" target="_blank" title="GitHub" rel="external nofollow"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tony.face2ai@gmail.com" target="_blank" title="E-Mail" rel="external nofollow"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://twitter.com/Tony_Face2AI" target="_blank" title="Twitter" rel="external nofollow"><i class="fa fa-fw fa-twitter"></i>Twitter</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#开篇废话"><span class="nav-number">1.</span> <span class="nav-text">开篇废话</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Marginal-Distribution"><span class="nav-number">2.</span> <span class="nav-text">Marginal Distribution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f"><span class="nav-number">3.</span> <span class="nav-text">Deriving a Marginal p.f. or a Marginal p.d.f.</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Discrete"><span class="nav-number">3.1.</span> <span class="nav-text">Discrete</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Continuous"><span class="nav-number">3.2.</span> <span class="nav-text">Continuous</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mixed"><span class="nav-number">4.</span> <span class="nav-text">Mixed</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Independent-Random-Variables"><span class="nav-number">5.</span> <span class="nav-text">Independent Random Variables</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-1"><span class="nav-number">5.1.</span> <span class="nav-text">判定独立方法 1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-2"><span class="nav-number">5.2.</span> <span class="nav-text">判定独立方法 2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-3"><span class="nav-number">5.3.</span> <span class="nav-text">判定独立方法 3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-4"><span class="nav-number">5.4.</span> <span class="nav-text">判定独立方法 4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-number">6.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#待续。。。。。"><span class="nav-number">7.</span> <span class="nav-text">待续。。。。。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#开篇废话-1"><span class="nav-number">8.</span> <span class="nav-text">开篇废话</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Marginal-Distribution-1"><span class="nav-number">9.</span> <span class="nav-text">Marginal Distribution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deriving-a-Marginal-p-f-or-a-Marginal-p-d-f-1"><span class="nav-number">10.</span> <span class="nav-text">Deriving a Marginal p.f. or a Marginal p.d.f.</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Discrete-1"><span class="nav-number">10.1.</span> <span class="nav-text">Discrete</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Continuous-1"><span class="nav-number">10.2.</span> <span class="nav-text">Continuous</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mixed-1"><span class="nav-number">11.</span> <span class="nav-text">Mixed</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Independent-Random-Variables-1"><span class="nav-number">12.</span> <span class="nav-text">Independent Random Variables</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-1-1"><span class="nav-number">12.1.</span> <span class="nav-text">判定独立方法 1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-2-1"><span class="nav-number">12.2.</span> <span class="nav-text">判定独立方法 2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-3-1"><span class="nav-number">12.3.</span> <span class="nav-text">判定独立方法 3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#判定独立方法-4-1"><span class="nav-number">12.4.</span> <span class="nav-text">判定独立方法 4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion-1"><span class="nav-number">13.</span> <span class="nav-text">Conclusion</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-"></i> </span><span class="author" itemprop="copyrightHolder">Tony</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/affix.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>