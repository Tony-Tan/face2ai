<!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=6.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=6.4.0"><link rel="mask-icon" href="/images/logo.png?v=6.4.0" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"6.4.0",sidebar:{position:"left",display:"remove",offset:12,b2t:!1,scrollpercent:!0,onmobile:!0},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="Abstract: 本文主要介绍事件的并集对应的概率计算，以及一个补充的概率小知识，怎么用统计骗人Keywords: Union of two Events，Union of Finite Number of Events，Statical Swindles"><meta name="keywords" content="Union of two Events,两个事件的并,Union of Finite Number of Events,有限个事件的并,Statical Swindles,概率欺骗"><meta property="og:type" content="article"><meta property="og:title" content="\[概率论\]1-4:事件的的并集(Union of Events and Statical Swindles)"><meta property="og:url" content="http://www.face2ai.com/Math-Probability-1-4-Union-of-Event/index.html"><meta property="og:site_name" content="谭升的博客"><meta property="og:description" content="Abstract: 本文主要介绍事件的并集对应的概率计算，以及一个补充的概率小知识，怎么用统计骗人Keywords: Union of two Events，Union of Finite Number of Events，Statical Swindles"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-1-4-Union-of-Event/two_events.png"><meta property="og:updated_time" content="2018-09-24T05:28:10.446Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="\[概率论\]1-4:事件的的并集(Union of Events and Statical Swindles)"><meta name="twitter:description" content="Abstract: 本文主要介绍事件的并集对应的概率计算，以及一个补充的概率小知识，怎么用统计骗人Keywords: Union of two Events，Union of Finite Number of Events，Statical Swindles"><meta name="twitter:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-1-4-Union-of-Event/two_events.png"><link rel="canonical" href="http://www.face2ai.com/Math-Probability-1-4-Union-of-Event/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>\[概率论\]1-4:事件的的并集(Union of Events and Statical Swindles) | 谭升的博客</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105335860-3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-105335860-3")</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">谭升的博客</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">人工智能基础</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-首页"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-集合论"><a href="/categories/Mathematic/Set-Theory/" rel="section">集合论</a></li><li class="menu-item menu-item-线性代数"><a href="/categories/Mathematic/Linear-Algebra/" rel="section">线性代数</a></li><li class="menu-item menu-item-概率论"><a href="/categories/Mathematic/Probability/" rel="section">概率论</a></li><li class="menu-item menu-item-数理统计学"><a href="/categories/Mathematic/Statistics/" rel="section">数理统计学</a></li><li class="menu-item menu-item-数值分析"><a href="/categories/Mathematic/Numerical-Analysis/" rel="section">数值分析</a></li><li class="menu-item menu-item-机器学习算法"><a href="/categories/Machine-Learning/" rel="section">机器学习算法</a></li><li class="menu-item menu-item-强化学习"><a href="/categories/Reinforcement-Learning/" rel="section">强化学习</a></li><li class="menu-item menu-item-深度学习算法"><a href="/categories/Deep-Learning/" rel="section">深度学习算法</a></li><li class="menu-item menu-item-数字图像处理"><a href="/categories/DIP/" rel="section">数字图像处理</a></li><li class="menu-item menu-item-30天自制操作系统"><a href="/categories/30天自制操作系统/" rel="section">30天自制操作系统</a></li><li class="menu-item menu-item-cuda"><a href="/categories/CUDA/" rel="section">CUDA</a></li><li class="menu-item menu-item-网络爬虫"><a href="/categories/Crawler/" rel="section">网络爬虫</a></li><li class="menu-item menu-item-乱七八糟"><a href="/categories/Other/" rel="section">乱七八糟</a></li></ul></nav><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.face2ai.com/Math-Probability-1-4-Union-of-Event/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="谭升"><meta itemprop="description" content="本站包括强化学习算法，机器学习算法，人工智能，CUDA编程，模式识别算法，线性代数，概率论，数理统计等人工智能原创博客"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="谭升的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">\[概率论\]1-4:事件的的并集(Union of Events and Statical Swindles)</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-01-30 09:22:40" itemprop="dateCreated datePublished" datetime="2018-01-30T09:22:40+08:00">2018-01-30</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/" itemprop="url" rel="index"><span itemprop="name">Mathematic</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/Probability/" itemprop="url" rel="index"><span itemprop="name">Probability</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数： <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Abstract:</strong> 本文主要介绍事件的并集对应的概率计算，以及一个补充的概率小知识，怎么用统计骗人<br><strong>Keywords:</strong> Union of two Events，Union of Finite Number of Events，Statical Swindles</p><a id="more"></a><h1 id="事件的的并集"><a href="#事件的的并集" class="headerlink" title="事件的的并集"></a>事件的的并集</h1><p>废话还是说说数学吧，学数学真的看不到立竿见影的事，相比学个C++、TensorFlow，这些更有成就感，毕竟写了就有结果可以看，数学学习的结果就是，你可能只会做两道题，没办法直接让你升值加薪，但是凡事都有因果，通过这几个月简单的学习，我发现身边的很多事都能用数学解释，比如今天要写的，如果我早些学习可能可以避免很多不必要的损失，而且通过学数学分析，可以通过一个人的语言来判断这个人的逻辑，进而判断这个人的性格，这是心理学的内容了，我不懂心理学，但是很感兴趣，如果有机会去研究下心理学，毕竟也跟人工智能强相关。<br>本篇介绍两个小知识点，关于事件的并集的概率求法，以及一些概率的日常应用</p><h2 id="两个事件的并-Union-of-Two-Events"><a href="#两个事件的并-Union-of-Two-Events" class="headerlink" title="两个事件的并 Union of Two Events"></a>两个事件的并 Union of Two Events</h2><p>在前面<a href="http://face2ai.com/Math-Probability-1-1-Definition-of-Probability/" target="_blank" rel="noopener">1-1概率定义</a>中的T7给出了两个相交的事件的并集的概率计算方法：<br>$$Pr(A\cup B)=Pr(A)+Pr(B)-Pr(A\cap B)$$<br>详细的证明在1-1中也有给出，这个公式在本文中将会进一步展开，把其延展到无数项，但是在开始之前我们还是来复习下这个定理，事件是试验结果的集合，集合的基本运算就是交，并，补，补集和概率的对应我们在1-1中的T3就是最基础的补集的概率计算，剩下就是交集和并集的计算了，T7给出了两个集合并集的概率计算公式，并给出了分析的证明方法，之前看书和上课老师都是给我们画个Venn图没然后说 $Pr(A\cup B)$ 是 $Pr(A)+Pr(B)$ 但是重复加了一遍 $Pr(A\cap B)$ 所以要减去。<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Math-Probability-1-4-Union-of-Event/two_events.png" alt=""></p><p>提到Venn图说一下，就是关于理解数学，到底是用图形化的可视化的方法好，还是分析法好，这个没办法一棍子打死，大学之前老师们都喜欢用画图的方法教大家理解概念知识点，原因是高中，初中，知识点极其少，更多是的各种拐弯的习题，所以为了加深大家的理解，画个图，直观，而且更容易被人接受，但是到了大学以后，画图就不再合适了，因为知识点变多，而且有很多没办法用二维三维的图来解释，所以，分析的方法到了大学以后是更有用的，拿机器学习的例子来说，做可视化是一个方向，但是这个方向的结果大多是为了展示给一些没有背景的人来看的，业内人士多半关注参数。</p><p>这里说了一大堆话的目的就是说明，分析到后面越来越有用，所以数学分析是数学系的开蒙课程。</p><h2 id="有限个事件的并-Union-of-Finite-Number-of-Events"><a href="#有限个事件的并-Union-of-Finite-Number-of-Events" class="headerlink" title="有限个事件的并 Union of Finite Number of Events"></a>有限个事件的并 Union of Finite Number of Events</h2><p>多个事件的并集，就是对上面“分析”理论的一个很好的诠释，当事件数量超过五个，Venn图马上就乱掉了，我们这里省去三个事件的并集的概率计算，直接进行更高难度的有限个事件的并集：</p><blockquote><p>Theorem For every events $A_1,\dots,A_n$ ,<br>$$<br>Pr(\bigcup^n_{i=1}A_i)=\sum^n_{i=1}Pr(A_i)-\sum_{i&lt;j}Pr(A_i\cap A_j)\\<br>+\sum_{i&lt;j&lt;k}(A_i\cap A_j \cap A_k)-\sum_{i&lt;j&lt;k&lt;l}(A_i\cap A_j\cap A_k \cap A_l)+\\<br>\dots + (-1)^{n+1}Pr(A_1\cap A_2 \cap \dots \cap A_n)<br>$$</p></blockquote><p>给出了个公式，证明过程其实就是一个分析过程，所以证明需要用数学语言来完成，而不是画个图放在那，那么我们来分析这个问题，首先这个公式的变量n是个自然数，那么最基础的方法就是归纳法。</p><ol><li>当$n=1$ 时，显然是成立的，其与1-1中的T7相等。</li><li>设当 $n=m$ 时成立<br>$$Pr(\bigcup^m_{i=1}A_i)=\sum^m_{i=1}Pr(A_i)-\sum_{i&lt;j}Pr(A_i\cap A_j)\\<br>+\sum_{i&lt;j&lt;k}(A_i\cap A_j \cap A_k)-\sum_{i&lt;j&lt;k&lt;l}(A_i\cap A_j\cap A_k \cap A_l)+\\<br>\dots + (-1)^{m+1}Pr(A_1\cap A_2 \cap \dots \cap A_m)$$</li><li>当 $n=m+1$ 时，我们套用$Pr(A\cup B)=Pr(A)+Pr(B)-Pr(A\cap B)$ 公式，</li></ol><ul><li>其中 $\bigcup^m_{i=1}A_i$ 为$A$，$A_{m+1}$ 为 $B$</li><li>那么，$A\cup B=\bigcup^{m+1}_{i=1}A_i$</li><li>最关键的是 $A\cap B=\bigcup^{m}_{i=1}(A_i\cap A_{m+1})$ ，可以根据集合论的工时得到，可以看到 $Pr(B)-Pr(A\cap B)$ 有：<br>$$<br>Pr(B)-Pr(A\cap B)=Pr(A_{m+1})-\sum^m_{i=1}Pr(A_i\cap A_{m+1})+\sum_{i&lt;j}Pr(A_i\cap A_j \cap A_{m+1})\\<br>-\sum_{i&lt;j&lt;k}(A_i\cap A_j \cap A_k \cap A_{m+1})+\sum_{i&lt;j&lt;k&lt;l}(A_i\cap A_j\cap A_k \cap A_l\cap A_{m+1})-\\<br>\dots + (-1)^{m+2}Pr(A_1\cap A_2 \cap \dots \cap A_{m+1}))<br>$$</li><li>最关键的是，当$n=m+1$ 时，$Pr(\bigcup^{m+1}_{i=1}A_i)-Pr(\bigcup^{m}_{i=1}A_i)$ 和上面的表达式一致(计算过程太复杂，所以，这里省略)</li><li>Q.E.D</li></ul><p>上述证明比较粗糙，大家可以自己计算下，对于有限时间的并集的概率计算大致的意思就是加多了减，减多了再加，直观的，可以通过画三个集合的Venn图来观察，分析的，就是上述的大致过程。</p><h2 id="匹配问题-Matching-Problem"><a href="#匹配问题-Matching-Problem" class="headerlink" title="匹配问题 Matching Problem"></a>匹配问题 Matching Problem</h2><p>上面是严格的数学证明，下面我们来分析一个简单但是有趣的应用，其中用到了多事件并集的概率计算，matching problem，配对或者叫做匹配游戏。<br>描述下问题，假设我们已有一个n个不同的符号的序列，我们来自己随便排列这n个符号的顺序（我们不知道这已有的排列顺序），如果我们排列的符号序列对应位置上的符号和已有符号能够对应上，就叫做一个match，那么当n变化的时候，match的概率$p_{n}$ 怎么描述呢？</p><blockquote><p>分析：</p><ul><li>假设第i个字母matching的事件为$A_i$，其概率$Pr(A_i)=\frac{1}{n}$，</li><li>如果有1个match(k=1):$\sum^{n}_{i=1}Pr(A_i)=n\cdot \frac{1}{n}=\frac{1}{1!}$</li><li>如果有2个match(k=2):$\sum^{n}_{i&lt;j}Pr(A_i\cap A_j)=\begin{pmatrix}n\\2\end{pmatrix}\cdot \frac{1}{n(n-1)}=\frac{1}{2!}$</li><li>如果有3个match(k=3):$\sum^{n}_{i&lt;j&lt;m}Pr(A_i\cap A_j\cap A_3)=\begin{pmatrix}n\\3\end{pmatrix}\cdot \frac{1}{n(n-1)(n-2)}=\frac{1}{3!}$</li><li>$\vdots$</li><li>如果有k个match: $\begin{pmatrix}n\\k\end{pmatrix}\cdot\frac{n!}{(n-k)!}=\frac{1}{k!}$</li><li>所以，根据我们上面证明多事件并集得到的公式$p_n=\frac{1}{1!}-\frac{1}{2!}+\frac{1}{3!}-\frac{1}{4!}\dots +(-1){n+1}\frac{1}{n!}$</li><li>当$lim_{n\to \infty}p_n=\frac{1}{1!}-\frac{1}{2!}+\frac{1}{3!}-\frac{1}{4!}\dots +(-1){n+1}\frac{1}{n!}=1-\frac{1}{e}\approx 0.63212$</li></ul></blockquote><p>也就是说当n无限多的时候，匹配成功的概率将会收敛到0.63212。我们可以发现当n=7的时候，写个小程序计算下结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="number">20</span></span><br><span class="line">result=<span class="number">1.0</span></span><br><span class="line">factorial=<span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,a,<span class="number">1</span>):</span><br><span class="line">    factorial=factorial * (i )</span><br><span class="line">    result+=(<span class="number">-1</span>)**(i+<span class="number">1</span>)*(<span class="number">1.0</span>/(factorial))</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'n='</span>+`i`+<span class="string">':'</span>+`result`</span><br></pre></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n=<span class="number">2</span>:<span class="number">0.5</span></span><br><span class="line">n=<span class="number">3</span>:<span class="number">0.6666666666666666</span></span><br><span class="line">n=<span class="number">4</span>:<span class="number">0.625</span></span><br><span class="line">n=<span class="number">5</span>:<span class="number">0.6333333333333333</span></span><br><span class="line">n=<span class="number">6</span>:<span class="number">0.6319444444444444</span></span><br><span class="line">n=<span class="number">7</span>:<span class="number">0.6321428571428571</span></span><br><span class="line">n=<span class="number">8</span>:<span class="number">0.6321180555555556</span></span><br><span class="line">n=<span class="number">9</span>:<span class="number">0.632120811287478</span></span><br><span class="line">n=<span class="number">10</span>:<span class="number">0.6321205357142857</span></span><br><span class="line">n=<span class="number">11</span>:<span class="number">0.6321205607663941</span></span><br><span class="line">n=<span class="number">12</span>:<span class="number">0.6321205586787184</span></span><br><span class="line">n=<span class="number">13</span>:<span class="number">0.6321205588393088</span></span><br><span class="line">n=<span class="number">14</span>:<span class="number">0.6321205588278381</span></span><br><span class="line">n=<span class="number">15</span>:<span class="number">0.6321205588286029</span></span><br><span class="line">n=<span class="number">16</span>:<span class="number">0.6321205588285551</span></span><br><span class="line">n=<span class="number">17</span>:<span class="number">0.6321205588285579</span></span><br><span class="line">n=<span class="number">18</span>:<span class="number">0.6321205588285578</span></span><br><span class="line">n=<span class="number">19</span>:<span class="number">0.6321205588285578</span></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure><p>仔细观察发现当n=7的时候，就已经开始收敛了，也就是说，后面再怎么增加n也不会影响其概率了。</p><h2 id="概率欺诈-Statistical-Swindles"><a href="#概率欺诈-Statistical-Swindles" class="headerlink" title="概率欺诈 Statistical Swindles"></a>概率欺诈 Statistical Swindles</h2><p>接下来这些话题都是属于知识联系实际的科普小软文，有事的同学可以先行离开了。</p><h3 id="统计滥用-Misleading-Using-of-Statistics"><a href="#统计滥用-Misleading-Using-of-Statistics" class="headerlink" title="统计滥用 Misleading Using of Statistics"></a>统计滥用 Misleading Using of Statistics</h3><p>马克吐温说过：“世界上的谎言有三种，谎言，无耻的谎言，统计”，“你可以通过统计证明任何事情。”<br>我们学习概率的另一个重要用途就是日常中不会被报纸新闻上的统计信息欺骗，通过已有知识的判断真实的情况。比如经常说的平均工资，人均收入，这些都是统计概念，相比对其真实性大家都有所怀疑。</p><h3 id="完美预测-Perfect-Forecasts"><a href="#完美预测-Perfect-Forecasts" class="headerlink" title="完美预测 Perfect Forecasts"></a>完美预测 Perfect Forecasts</h3><p>神预测，如果一个投资公司每周一给你推送一只股票，这个股票本周大涨50%，第二周又给你推送了另一只，结果又是大涨50%，第三周第四周，周周如此，你是不是会觉得，卧槽，发财的机会来了，卖房卖地卖媳妇也要进去赚一笔，但是实际投资公司不是神，只是耍了你而已。<br>他们的做法是什么呢？<br>首先我们假定其推送的股票涨50%的概率是$Pr=\frac{1}{n}$，那么他们想保证k周有人连续正确，他们只需要发给$n^k$ 个人就可以了</p><ul><li>第一周，发送给所有人</li><li>第二周，发给第一周正确地人，正确的人数大概在$n^{k-1}$ 左右</li><li>第三周，发给第二周正确地人，正确的人数大概在$n^{k-2}$ 左右</li><li>第四周，发给第二周正确地人，正确的人数大概在$n^{k-3}$ 左右</li><li>$\vdots$</li><li>第k周，发给第k-1周正确地人，正确的人数大概在$1$左右</li></ul><p>怎么样，如果他连续发给你一年都是正确的，可以保证，这个人有内幕消息，估计那样他根本不用发给你，他自己可以卖车卖房卖媳妇，而没必要从你身上赚取服务费了。<br>完美预测，需要的要么是人多，要么就是概率高一些。</p><h3 id="保证胜利-Guaranteed-Winner"><a href="#保证胜利-Guaranteed-Winner" class="headerlink" title="保证胜利 Guaranteed Winner"></a>保证胜利 Guaranteed Winner</h3><p>保证胜利，看球赛，有公司这么搞，给你推荐获胜球队，你可以去买彩票或者赌球，推荐对的收取一定服务费，不对不收费，你看起来这事没问题，稳赚不赔，但是，从概率的角度分析，他并不能提高你的获奖概率，而且当你获奖时他要收取服务费，当他没有内幕消息的时候，这个完全是骗人的，而这些公司完全没有任何风险，按照一定的比例给不同的人，推送不同的获胜方，这样他肯定会有收入（肯定会有正确的），具体怎么将收入最大化，那就是优化问题，</p><h3 id="买彩票-Improving-Your-Lottery-Chances"><a href="#买彩票-Improving-Your-Lottery-Chances" class="headerlink" title="买彩票 Improving Your Lottery Chances"></a>买彩票 Improving Your Lottery Chances</h3><p>买彩票，不知道大家有没有买过，我买过，我发现每期都有两个连续的数字，我们来分析下这种现象是否有概率依据。<br>假设我们的彩票是40个数字选6个，without replacement，各个数字间没有影响，那么这个模型就是个见得组合，那么一共有：<br>$$<br>\begin{pmatrix}40\\6\end{pmatrix}=3,838,380<br>$$<br>种组合，一等奖，全部命中的概率是 $\frac{1}{3,838,380}$ 那么出现至少两个连续的号码呢？结果是大约有0.577的概率，怎么算？你可以先算出所有号都不连续的组合方式，然后用1-1中的T3，就可以得到一个大概的数字，因为这个存在一个边界的问题，所以还是要小心一点。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>学习知识，就不会被人骗了，哈哈哈哈，明天继续。。</p><p>原文地址1：<a href="https://www.face2ai.com/Math-Probability-1-4-Union-of-Event">https://www.face2ai.com/Math-Probability-1-4-Union-of-Event</a>转载请标明出处</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>谭升</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://www.face2ai.com/Math-Probability-1-4-Union-of-Event/" title="\[概率论\]1-4:事件的的并集(Union of Events and Statical Swindles)">http://www.face2ai.com/Math-Probability-1-4-Union-of-Event/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Math-Probability-1-3-Combinatorial-Methods/" rel="next" title="\[概率论\]1-3:组合(Combinatorial Methods)"><i class="fa fa-chevron-left"></i> \[概率论\]1-3:组合(Combinatorial Methods)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/Math-Probability-2-1-Conditional-Probability/" rel="prev" title="\[概率论\]2-1:条件概率(Conditional Probability)">\[概率论\]2-1:条件概率(Conditional Probability) <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/weixingongzhonghao.jpg" alt="wechat"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-"></i> </span><span class="author" itemprop="copyrightHolder">谭升</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>