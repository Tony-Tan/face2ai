<!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=6.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=6.4.0"><link rel="mask-icon" href="/images/logo.png?v=6.4.0" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"6.4.0",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!0},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="Abstract: 本文介绍负二项分布，几何分布的基础知识Keywords: The Negative Binomial Distribution，The Geometric Distribution"><meta name="keywords" content="The Negative Binomial Distribution,The Geometric Distribution"><meta property="og:type" content="article"><meta property="og:title" content="\[概率论\]5-5:负二项分布(The Negative Binomial Distribution)"><meta property="og:url" content="http://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution/index.html"><meta property="og:site_name" content="强化学习，机器学习，人工智能"><meta property="og:description" content="Abstract: 本文介绍负二项分布，几何分布的基础知识Keywords: The Negative Binomial Distribution，The Geometric Distribution"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2018-09-24T04:28:20.061Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="\[概率论\]5-5:负二项分布(The Negative Binomial Distribution)"><meta name="twitter:description" content="Abstract: 本文介绍负二项分布，几何分布的基础知识Keywords: The Negative Binomial Distribution，The Geometric Distribution"><link rel="canonical" href="http://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>\[概率论\]5-5:负二项分布(The Negative Binomial Distribution) | 强化学习，机器学习，人工智能</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105335860-3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-105335860-3")</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">强化学习，机器学习，人工智能</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">谭升的博客</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-首页"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-数学"><a href="/categories/Mathematic/" rel="section">数学</a></li><li class="menu-item menu-item-···-集合论"><a href="/categories/Mathematic/Set-Theory/" rel="section">··· 集合论</a></li><li class="menu-item menu-item-···-线性代数"><a href="/categories/Mathematic/Linear-Algebra/" rel="section">··· 线性代数</a></li><li class="menu-item menu-item-···-概率论"><a href="/categories/Mathematic/Probability/" rel="section">··· 概率论</a></li><li class="menu-item menu-item-···-数理统计学"><a href="/categories/Mathematic/Statistics/" rel="section">··· 数理统计学</a></li><li class="menu-item menu-item-···-数值分析"><a href="/categories/Mathematic/Numerical-Analysis/" rel="section">··· 数值分析</a></li><li class="menu-item menu-item-机器学习算法"><a href="/categories/Machine-Learning/" rel="section">机器学习算法</a></li><li class="menu-item menu-item-强化学习"><a href="/categories/Reinforcement-Learning/" rel="section">强化学习</a></li><li class="menu-item menu-item-深度学习算法"><a href="/categories/Deep-Learning/" rel="section">深度学习算法</a></li><li class="menu-item menu-item-数字图像处理"><a href="/categories/DIP/" rel="section">数字图像处理</a></li><li class="menu-item menu-item-30天自制操作系统"><a href="/categories/30天自制操作系统/" rel="section">30天自制操作系统</a></li><li class="menu-item menu-item-cuda"><a href="/categories/CUDA/" rel="section">CUDA</a></li><li class="menu-item menu-item-网络爬虫"><a href="/categories/Crawler/" rel="section">网络爬虫</a></li><li class="menu-item menu-item-乱七八糟"><a href="/categories/Other/" rel="section">乱七八糟</a></li></ul></nav><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="谭升"><meta itemprop="description" content="本站包括强化学习算法，机器学习算法，人工智能，CUDA编程，模式识别算法，线性代数，概率论，数理统计等人工智能原创博客"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="强化学习，机器学习，人工智能"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">\[概率论\]5-5:负二项分布(The Negative Binomial Distribution)</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-03-29 08:57:12" itemprop="dateCreated datePublished" datetime="2018-03-29T08:57:12+08:00">2018-03-29</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/" itemprop="url" rel="index"><span itemprop="name">Mathematic</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/Probability/" itemprop="url" rel="index"><span itemprop="name">Probability</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数： <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Abstract:</strong> 本文介绍负二项分布，几何分布的基础知识<br><strong>Keywords:</strong> The Negative Binomial Distribution，The Geometric Distribution</p><a id="more"></a><h1 id="开篇废话"><a href="#开篇废话" class="headerlink" title="开篇废话"></a>开篇废话</h1><p>到目前为止，所有的分部都是从Bernoulli 分布衍生出来的：</p><ol><li>二项分布，$n$ 次Bernoulli试验的结果中，每次试验的分布不变，结果为1的次数 $X$ 的分布</li><li>超几何分布，$n$ 次Bernoulli试验，每次试验分布发生改变，结果为1的次数 $X$ 的分布，当试验分布变化不大的时候和二项分布结果相同</li><li>泊松分布，用来在某种特殊情况下（$n$ 比较大， $p$ 比较小，而 $np$ 又不是很大的情况下）近似二项分布，当n趋近于无穷的时候等同于二项分布。</li></ol><p>今天我们还是从二项分布出发，研究这样一个事实，对于Bernoulli过程，我们设定，当某个结果出现固定次数的时候，整个过程的数量，比如我们生产某个零件，假设每个零件的合格与否都是相互独立的，且分布相同，那么当我们生产出了五个不合格零件时，一共生产了多少合格的零件，这个数量就是一个负二项分布。<br>为什么叫负二项分布而不是正二项分布？<br>有两种说法，第一我们上面说到的例子，多半是失败到了固定次数时 $X$ 的分布，另一种是站在分布的系数上来观察的，在下面我们可以看得到。</p><h1 id="负二项分布的定义和含义-Definition-and-Interpretation"><a href="#负二项分布的定义和含义-Definition-and-Interpretation" class="headerlink" title="负二项分布的定义和含义 Definition and Interpretation"></a>负二项分布的定义和含义 Definition and Interpretation</h1><p>废话中给出的生产零件的例子就是引出定义的关键。我们来先看一个定理，描述上面过程的定理：</p><blockquote><p>Theorem Sampling until a Fixed Number of Success.Suppose that an infinite sequence of Bernoulli trails with probability of success $p$ are available.The number $X$ of failures that occur before the $r$th success has the following p.d.f.<br>$$<br>f(x|r,p)=<br>\begin{cases}<br>\begin{pmatrix}<br>r+x-1\\<br>x<br>\end{pmatrix}p^r(1-p)^x&amp;\text{for }x=0,1,2,\dots\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$</p></blockquote><p>证明如下<br>首先我们必须分析一下这个过程，当成功的次数达到目标后停止试验，也就是说最后一次必然是成功的，不然试验不会结束，所以我们需要的是在已经进行了的 $x+r-1$ 次实验中完成 $r-1$ 次成功，$x$ 次失败，那么从计数原理角度，概率为：<br>$$<br>\begin{aligned}<br>Pr(A_n)&amp;=\begin{pmatrix}n-1\\r-1\end{pmatrix}p^{r-1}(1-p)^{(n-1)-(r-1)}p\\<br>&amp;=\begin{pmatrix}n-1\\r-1\end{pmatrix}p^{r}(1-p)^{(n-r)}p<br>\end{aligned}<br>$$<br>然后这就是我们的目标了，n就是总的试验次数包括成功和失败。</p><blockquote><p>Definition Negative Binomial Distribution.A random variable $X$ has the negative binomial distribution with parameters $r$ and $p$ ( $r=1,2,\dots$ and $0 &lt; p &lt; 1$) if $X$ has a discrete distribution for which the p.f. $f(x|r,p)$ is as specified by theorem upside.</p></blockquote><p>定义，告诉你，上面定理里面的p.f.叫负二项分布<br>因为存在关系：<br>$$<br>\begin{pmatrix}<br>r+x-1\\<br>x<br>\end{pmatrix}={\frac {(x+r-1)\dotsm (r)}{x!}}=(-1)^{x}{\frac {(-r)(-r-1)(-r-2)\dotsm (-r-k+1)}{x!}}=(-1)^{x}{\binom {-r}{x}}<br>$$<br>所以负二项分布可以写成：<br>$$<br>f(x|r,p)=<br>\begin{cases}<br>(-1)^{x}{\binom {-r}{x}}p^r(1-p)^x&amp;\text{for }x=0,1,2,\dots\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$<br>这就是命名的由来（参考《统计推断第二版》）</p><h1 id="几何分布-The-Geometric-Distribution"><a href="#几何分布-The-Geometric-Distribution" class="headerlink" title="几何分布 The Geometric Distribution"></a>几何分布 The Geometric Distribution</h1><p>我们先学了超几何分布然后又跑回来学几何分布，难道我们跑错了？当然不是，因为几何分布跟负二项分布非常相关。<br>当负二项分布 $r=1$ 的时候产生的分布叫做几何分布，文字解释就是当我们第一个不合格的产品出现时，我们就停止生产，这是生产的合格产品的数量为随机变量 $X$</p><blockquote><p>Definition Geometric Distribution.A random varibale X has the geometric distribution with parameter p ($0 &lt; p &lt; 1$ )if X has a discrete distribution for which the p.f. f(x|1,p) is as follows:<br>$$<br>f(x|1,p)=<br>\begin{cases}<br>p(1-p)^x&amp;\text{for }x=0,1,2,\dots\\<br>0&amp;\text{otherwise}<br>\end{cases}<br>$$</p></blockquote><p>这个跟负二项分布一模一样，所以就不再重复证明了</p><blockquote><p>Theorem if $X_1,\dots,X_r$ are i.i.d. random variable and if each $X_i$ has the geometric distribution with parameter $p$ ,then the sum $X_1+\dots+X_r$ has the negative binomial distribution with parameters $r$ and $p</p></blockquote><p>又是加法规则，多个几何分布相加的结果是负二项分布。<br>证明过程也就是分析过程，首先我们假设我们有一个Bernoulli过程，那么如果只要有0发生就停止，这样产生的是几何分布，如果第一个几何分布 $X_i$ 产生以后，我们继续按照规则进行，那么接着会产生 $X_2,\dots,X_n$ 并且之间相互独立，而产生的到第 $n$ 个的时候，就产生了一个当0发生 $n$ 次的负二项分布。所以这 $n$ 个随机变量相加就是负二项分布。</p><p>这个证明不太严谨。但是从逻辑的角度上是成立的。</p><h1 id="负二项分布和几何分布的性质-Properties-of-Negative-Binomial-and-Geometric-Distributions"><a href="#负二项分布和几何分布的性质-Properties-of-Negative-Binomial-and-Geometric-Distributions" class="headerlink" title="负二项分布和几何分布的性质 Properties of Negative Binomial and Geometric Distributions"></a>负二项分布和几何分布的性质 Properties of Negative Binomial and Geometric Distributions</h1><p>接下来我们看看性质</p><h2 id="距生成函数-m-g-f"><a href="#距生成函数-m-g-f" class="headerlink" title="距生成函数 m.g.f."></a>距生成函数 m.g.f.</h2><blockquote><p>Theorem Moment Generating Function.If X has the negative binomial distribution with parameters r and p ,then the m.g.f. of X is as follow:<br>$$<br>\psi(t)=(\frac{p}{1-(1-p)e^t})^r\text{ for } t&lt; log(\frac{1}{1-p})<br>$$<br>$r=1$ 的时候上述表达式为几何分布的p.d.f. ，有点复杂了，我们来证明下。</p></blockquote><p>证明：<br>要用到m.g.f.的定理就是多个独立的随机变量和的m.g.f.是其m.g.f.的积：</p><blockquote><p>Teorem 4.4.4 Suppose that $X_1,\dots,X_n$ are $n$ independent random varibales;and for $i=1,\dots,n$ . let $\psi_i$ denote the m.g.f. of $X_i$ .Let $Y=X_1+\dots+X_n$ ,and let the m.g.f. of $Y$ be denoted by $\psi$ .Then for every value of t such that $\psi_i(t)$ is finite for $i=1,\dots,n$ ,<br>$$<br>\psi(t)=\Pi^{n}_{i=1}\psi_i(t)<br>$$</p></blockquote><p>以及上面的定理：多个同参数 $p$ 的独立几何分布的和是负二项分布，假设这些i.i.d的随机变量为 $X_1,\dots,X_n$<br>于是：<br>$$<br>\psi_i(t)=E(e^{tX_i})=p\sum^{\infty}_{x=0}[(1-p)e^t]^x<br>$$<br>为了使上面的表达式结果有限，或者说让 $[(1-p)e^t]^x$ 收敛，我们应该有 $0&lt; (1-p)e^t &lt; 1$ 得到 $t&lt;log(\frac{1}{1-p})$<br>根据微积分中级数的原理，当 $\alpha\in (0,1)$ 时：<br>$$<br>\sum^{\infty}_{x=0}\alpha^x=\frac{1}{1-\alpha}<br>$$</p><p>带入到 $\psi_i(t)$ 中就有<br>$$<br>\psi_i(t)=\frac{p}{1-(1-p)e^t}<br>$$</p><p>那么根据上面的定理4.4.4 我们就能得到结果<br>$$<br>\psi(t)=(\frac{p}{1-(1-p)e^t})^r\text{ for } t&lt; log(\frac{1}{1-p})<br>$$</p><h2 id="均值和方差-Mean-and-Variance"><a href="#均值和方差-Mean-and-Variance" class="headerlink" title="均值和方差 Mean and Variance"></a>均值和方差 Mean and Variance</h2><blockquote><p>Theorem if $X$ has the negative binomial distribution with parameters $r$ and $p$ the mean and the varance of $X$ must be<br>$$<br>E(X)=\frac{r(1-p)}{p} \text{ and }Var(X)\frac{r(1-p)}{p^2}<br>$$<br>The mean and variance of the geometric distribution with parameter $p$ are the special case of equation upsite with $r=1$</p></blockquote><p>如果有了m.g.f.求均值和方差都不是大问题，就是求两个导数，所以就直接写结果了，但是我们有更简单的方法，继续把负二项分布拆成几何分布，然后计算均值和方差后按照均值和方差的加法原则求负二项分布的均值和方差：<br>$$<br>E(X_i)=\psi’_i(0)=\frac{1-p}{p}\\<br>Var(X_i)=\psi’’_i(0)-[\psi’_i(0)]^2=\frac{1-p}{p^2}<br>$$<br>然后就是把 $r$ 个 $X_i$ 求和就得到订立中的结果了。</p><h2 id="集合分布的无记忆性-Memorless-Property-of-Geometric-Distributions"><a href="#集合分布的无记忆性-Memorless-Property-of-Geometric-Distributions" class="headerlink" title="集合分布的无记忆性 Memorless Property of Geometric Distributions"></a>集合分布的无记忆性 Memorless Property of Geometric Distributions</h2><p>这条性质是第一次出现，所以值得注意</p><blockquote><p>Theorem Memoryless Property of Geometric Distributions.Let $X$ have the geometric distribution with parameter $p$ ,and let $k\geq 0$ .Then for every integer $t\geq 0$ ,<br>$$<br>Pr(X=k+t|X\geq k)=Pr(X=t)<br>$$</p></blockquote><p>这个证明是个习题，我还没有做（嘻嘻嘻，后面补上），但是要指出的是，我们学的这些分布中只有几何分布有这种性质。</p><font color="ff000">此处有坑，记得补上</font><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文介绍了离散分布中最后两个，负二项分布，和几何分布，下一篇开始连续分布。</p><p>原文地址1：<a href="https://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution">https://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution</a>转载请标明出处</p></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>可怜可怜我吧</div><button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/weixin.png" alt="谭升 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"><img id="alipay_qr" src="/images/alipay.png" alt="谭升 支付宝"><p>支付宝</p></div></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>谭升</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution/" title="\[概率论\]5-5:负二项分布(The Negative Binomial Distribution)">http://www.face2ai.com/Math-Probability-5-5-The-Negative-Binomial-Distribution/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Math-Probability-5-4-The-Poisson-Distribution/" rel="next" title="\[概率论\]5-4:泊松分布(The Poisson Distribution)"><i class="fa fa-chevron-left"></i> \[概率论\]5-4:泊松分布(The Poisson Distribution)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/Math-Probability-5-6-The-Normal-Distributions-P1/" rel="prev" title="\[概率论\]5-6:正态分布(The Normal Distributions Part I)">\[概率论\]5-6:正态分布(The Normal Distributions Part I) <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/weixingongzhonghao.jpg" alt="wechat"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="谭升"><p class="site-author-name" itemprop="name">谭升</p><p class="site-description motion-element" itemprop="description">本站包括强化学习算法，机器学习算法，人工智能，CUDA编程，模式识别算法，线性代数，概率论，数理统计等人工智能原创博客</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">260</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">18</span> <span class="site-state-item-name">分类</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tony-tan" target="_blank" title="GitHub" rel="external nofollow"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tony.face2ai@gmail.com" target="_blank" title="E-Mail" rel="external nofollow"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://twitter.com/Tony_Face2AI" target="_blank" title="Twitter" rel="external nofollow"><i class="fa fa-fw fa-twitter"></i>Twitter</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#开篇废话"><span class="nav-number">1.</span> <span class="nav-text">开篇废话</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#负二项分布的定义和含义-Definition-and-Interpretation"><span class="nav-number">2.</span> <span class="nav-text">负二项分布的定义和含义 Definition and Interpretation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#几何分布-The-Geometric-Distribution"><span class="nav-number">3.</span> <span class="nav-text">几何分布 The Geometric Distribution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#负二项分布和几何分布的性质-Properties-of-Negative-Binomial-and-Geometric-Distributions"><span class="nav-number">4.</span> <span class="nav-text">负二项分布和几何分布的性质 Properties of Negative Binomial and Geometric Distributions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#距生成函数-m-g-f"><span class="nav-number">4.1.</span> <span class="nav-text">距生成函数 m.g.f.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#均值和方差-Mean-and-Variance"><span class="nav-number">4.2.</span> <span class="nav-text">均值和方差 Mean and Variance</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集合分布的无记忆性-Memorless-Property-of-Geometric-Distributions"><span class="nav-number">4.3.</span> <span class="nav-text">集合分布的无记忆性 Memorless Property of Geometric Distributions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-"></i> </span><span class="author" itemprop="copyrightHolder">谭升</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/affix.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>