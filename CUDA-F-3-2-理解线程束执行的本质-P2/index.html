<!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=6.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=6.4.0"><link rel="mask-icon" href="/images/logo.png?v=6.4.0" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"6.4.0",sidebar:{position:"left",display:"remove",offset:12,b2t:!1,scrollpercent:!0,onmobile:!0},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="Abstract: 本文介绍CUDA线程束执行的本质的后半部分，包括资源，延迟，同步，扩展性等严重影响性能的线，吞吐量，带宽，占用率，CUDA同步"><meta name="keywords" content="CUDA资源分配,CUDA延迟隐藏,吞吐量,带宽,占用率,CUDA同步"><meta property="og:type" content="article"><meta property="og:title" content="\[CUDA 基础\]3.2 理解线程束执行的本质(Part II)"><meta property="og:url" content="http://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2/index.html"><meta property="og:site_name" content="谭升的博客"><meta property="og:description" content="Abstract: 本文介绍CUDA线程束执行的本质的后半部分，包括资源，延迟，同步，扩展性等严重影响性能的线，吞吐量，带宽，占用率，CUDA同步"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_13.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_14.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_2.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_15.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_16.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_3.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_4.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/devinf.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/excel.png"><meta property="og:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_18.png"><meta property="og:updated_time" content="2018-09-24T07:02:17.582Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="\[CUDA 基础\]3.2 理解线程束执行的本质(Part II)"><meta name="twitter:description" content="Abstract: 本文介绍CUDA线程束执行的本质的后半部分，包括资源，延迟，同步，扩展性等严重影响性能的线，吞吐量，带宽，占用率，CUDA同步"><meta name="twitter:image" content="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_13.png"><link rel="canonical" href="http://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>\[CUDA 基础\]3.2 理解线程束执行的本质(Part II) | 谭升的博客</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105335860-3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-105335860-3")</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">谭升的博客</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">人工智能基础</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-首页"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-集合论"><a href="/categories/Mathematic/Set-Theory/" rel="section">集合论</a></li><li class="menu-item menu-item-线性代数"><a href="/categories/Mathematic/Linear-Algebra/" rel="section">线性代数</a></li><li class="menu-item menu-item-概率论"><a href="/categories/Mathematic/Probability/" rel="section">概率论</a></li><li class="menu-item menu-item-数理统计学"><a href="/categories/Mathematic/Statistics/" rel="section">数理统计学</a></li><li class="menu-item menu-item-数值分析"><a href="/categories/Mathematic/Numerical-Analysis/" rel="section">数值分析</a></li><li class="menu-item menu-item-机器学习算法"><a href="/categories/Machine-Learning/" rel="section">机器学习算法</a></li><li class="menu-item menu-item-强化学习"><a href="/categories/Reinforcement-Learning/" rel="section">强化学习</a></li><li class="menu-item menu-item-深度学习算法"><a href="/categories/Deep-Learning/" rel="section">深度学习算法</a></li><li class="menu-item menu-item-数字图像处理"><a href="/categories/DIP/" rel="section">数字图像处理</a></li><li class="menu-item menu-item-30天自制操作系统"><a href="/categories/30天自制操作系统/" rel="section">30天自制操作系统</a></li><li class="menu-item menu-item-cuda"><a href="/categories/CUDA/" rel="section">CUDA</a></li><li class="menu-item menu-item-网络爬虫"><a href="/categories/Crawler/" rel="section">网络爬虫</a></li><li class="menu-item menu-item-乱七八糟"><a href="/categories/Other/" rel="section">乱七八糟</a></li></ul></nav><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="谭升"><meta itemprop="description" content="本站包括强化学习算法，机器学习算法，人工智能，CUDA编程，模式识别算法，线性代数，概率论，数理统计等人工智能原创博客"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="谭升的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">\[CUDA 基础\]3.2 理解线程束执行的本质(Part II)</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-03-15 20:08:09" itemprop="dateCreated datePublished" datetime="2018-03-15T20:08:09+08:00">2018-03-15</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CUDA/Freshman/" itemprop="url" rel="index"><span itemprop="name">Freshman</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数： <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Abstract:</strong> 本文介绍CUDA线程束执行的本质的后半部分，包括资源，延迟，同步，扩展性等严重影响性能的线，吞吐量，带宽，占用率，CUDA同步</p><a id="more"></a><h1 id="理解线程束执行的本质-Part-II"><a href="#理解线程束执行的本质-Part-II" class="headerlink" title="理解线程束执行的本质(Part II)"></a>理解线程束执行的本质(Part II)</h1><p>最近这几篇应该是CUDA最核心的部分，并不是编程模型，而是执行模型，通过执行模型我们去了解GPU硬件的具体运行方式，这样才能保证我们写出更快更好的程序。<br>由于访问量太少，转载请保留本条广告，各位老铁欢迎访问Tony的网站：<a href="http://www.face2ai.com">http://www.face2ai.com</a></p><h2 id="资源分配"><a href="#资源分配" class="headerlink" title="资源分配"></a>资源分配</h2><p>我们前面提到过，每个SM上执行的基本单位是线程束，也就是说，单指令通过指令调度器广播给某线程束的全部线程，这些线程同一时刻执行同一命令，当然也有分支情况，上一篇我们已经介绍了分支，这是执行的那部分，当然后有很多线程束没执行，那么这些没执行的线程束情况又如何呢？我给他们分成了两类，注意是我分的，不一定官方是不是这么讲。我们离开线程束内的角度（线程束内是观察线程行为，离开线程束我们就能观察线程束的行为了），一类是已经激活的，也就是说这类线程束其实已经在SM上准备就绪了，只是没轮到他执行，这时候他的状态叫做阻塞，还有一类可能分配到SM了，但是还没上到片上，这类我称之为未激活线程束。<br>而每个SM上有多少个线程束处于激活状态，取决于以下资源：</p><ul><li>程序计数器</li><li>寄存器</li><li>共享内存</li></ul><p>线程束一旦被激活来到片上，那么他就不会再离开SM直到执行结束。<br>每个SM都有32位的寄存器组，每个架构寄存器的数量不一样，其存储于寄存器文件中，为每个线程进行分配，同时，固定数量的共享内存，在线程块之间分配。<br>一个SM上被分配多少个线程块和线程束取决于SM中可用的寄存器和共享内存，以及内核需要的寄存器和共享内存大小。</p><p>这是一个平衡问题，就像一个固定大小的坑，能放多少萝卜取决于坑的大小和萝卜的大小，相比于一个大坑，小坑内可能放十个小萝卜，或者两个大萝卜，SM上资源也是，当kernel占用的资源较少，那么更多的线程（这是线程越多线程束也就越多）处于活跃状态，相反则线程越少。<br>关于寄存器资源的分配：</p><p><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_13.png" alt=""></p><p>关于共享内存的分配：</p><p><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_14.png" alt=""></p><p>上面讲的主要是线程束，如果从逻辑上来看线程块的话，可用资源的分配也会影响常驻线程块的数量。<br>特别是当SM内的资源没办法处理一个完整块，那么程序将无法启动，这个是我们应该找找自己的毛病，你得把内核写的多大，或者一个块有多少线程，才能出现这种情况。</p><p>以下是资源列表：</p><p><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_2.png" alt=""></p><p>当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。<br>活跃的线程束又分为三类：</p><ul><li>选定的线程束</li><li>阻塞的线程束</li><li>符合条件的线程束</li></ul><p>当SM要执行某个线程束的时候，执行的这个线程束叫做选定的线程束，准备要执行的叫符合条件的线程束，如果线程束不符合条件还没准备好就是阻塞的线程束。<br>满足下面的要求，线程束才算是符合条件的：</p><ul><li>32个CUDA核心可以用于执行</li><li>执行所需要的资源全部就位</li></ul><p>Kepler活跃的线程束数量从开始到结束不得大于64，可以等于。<br>任何周期选定的线程束小于等于4。<br>由于计算资源是在线程束之间分配的，且线程束的整个生命周期都在片上，所以线程束的上下文切换是非常快速的，。<br>下面我们介绍如何通过大量的活跃的线程束切换来隐藏延迟</p><h2 id="延迟隐藏"><a href="#延迟隐藏" class="headerlink" title="延迟隐藏"></a>延迟隐藏</h2><p>延迟隐藏，延迟是什么，就是当你让计算机帮你算一个东西的时候计算需要用的时间，举个宏观的例子，比如一个算法验证，你交给计算机，计算机会让某个特定的计算单元完成这个任务，共需要十分钟，而接下来这十分钟，你就要等待，等他算完了你才能计算下一个任务，那么这十分钟计算机的利用率有可能并不是100%，也就是说他的某些功能是空闲的，你就想能不能再跑一个同样的程序不同的数据（做过机器学习的这种情况不会陌生，大家都是同时跑好几个版本）然后你又让计算机跑，这时候你发现还没有完全利用完资源，于是有继续加任务给计算机，结果加到第十分钟了，已经加了十个了，你还没加完，但是第一个任务已经跑完了，如果你这时候停止加任务，等陆陆续续的你后面加的任务都跑完了共用时20分钟，共执行了10个任务，那么平局一个任务用时 $\frac{20}{10}=2$ 分钟/任务 。 但是我们还有一种情况，因为任务还有很多，第十分钟你的第一个任务结束的时候你继续向你的计算机添加任务，那么这个循环将继续进行，那么第二十分钟你停止添加任务，等待第三十分钟所有任务执行完，那么平均每个任务的时间是： $\frac{30}{20}=1.5$ 分钟/任务，如果一直添加下去，$lim_{n\to\infty}\frac{n+10}{n}=1$ 也就是极限速度，一分钟一个，隐藏了9分钟的延迟。<br>当然上面的另一个重要参数是每十分钟添加了10个任务，如果每十分钟共可以添加100个呢，那么二十分钟就可以执行100个，每个任务耗时： $\frac{20}{100}=0.2$ 分钟/任务 三十分钟就是 $\frac{30}{200}=0.15$ 如果一直添加下去， $lim_{n\to\infty}\frac{n+10}{n\times 10}=0.1$ 分钟/任务 。<br>这是理想情况，有一个必须考虑的就是虽然你十分钟添加了100个任务，可是没准添加50个计算机就满载了，这样的话 极限速度只能是：$lim_{n\to\infty}\frac{n+10}{n\times 5}=0.2$ 分钟/任务 了。</p><p>所以最大化是要最大化硬件，尤其是计算部分的硬件满跑，都不闲着的情况下利用率是最高的，总有人闲着，利用率就会低很多，即最大化功能单元的利用率。利用率与常驻线程束直接相关。<br>硬件中线程调度器负责调度线程束调度，当每时每刻都有可用的线程束供其调度，这时候可以达到计算资源的完全利用，以此来保证通过其他常驻线程束中发布其他指令的，可以隐藏每个指令的延迟。</p><p>与其他类型的编程相比，GPU的延迟隐藏及其重要。对于指令的延迟，通常分为两种：</p><ul><li>算术指令</li><li>内存指令</li></ul><p>算数指令延迟是一个算术操作从开始，到产生结果之间的时间，这个时间段内只有某些计算单元处于工作状态，而其他逻辑计算单元处于空闲。<br>内存指令延迟很好理解，当产生内存访问的时候，计算单元要等数据从内存拿到寄存器，这个周期是非常长的。<br>延迟：</p><ul><li>算术延迟 10~20 个时钟周期</li><li>内存延迟 400~800 个时钟周期</li></ul><p>下图就是阻塞线程束到可选线程束的过程逻辑图：<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_15.png" alt=""><br>其中线程束0在阻塞两短时间后恢复可选模式，但是在这段等待时间中，SM没有闲置。<br>那么至少需要多少线程，线程束来保证最小化延迟呢？<br>little法则给出了下面的计算公式<br>$$<br>\text{所需线程束} = \text{延迟} \times \text{吞吐量}<br>$$</p><blockquote><p>注意带宽和吞吐量的区别，带宽一般指的是理论峰值，最大每个时钟周期能执行多少个指令，吞吐量是指实际操作过程中每分钟处理多少个指令。</p></blockquote><p>这个可以想象成一个瀑布，像这样，绿箭头是线程束，只要线程束足够多，吞吐量是不会降低的：<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_16.png" alt=""><br>下面表格给出了Fermi 和Kepler执行某个简单计算时需要的并行操作数：<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_3.png" alt=""></p><p>另外有两种方法可以提高并行：</p><ul><li>指令级并行(ILP): 一个线程中有很多独立的指令</li><li>线程级并行(TLP): 很多并发地符合条件的线程</li></ul><p>同样，与指令周期隐藏延迟类似，内存隐藏延迟是靠内存读取的并发操作来完成的，需要注意的是，指令隐藏的关键目的是使用全部的计算资源，而内存读取的延迟隐藏是为了使用全部的内存带宽，内存延迟的时候，计算资源正在被别的线程束使用，所以我们不考虑内存读取延迟的时候计算资源在做了什么，这两种延迟我们看做两个不同的部门但是遵循相同的道理。<br>我们的根本目的是把计算资源，内存读取的带宽资源全部使用满，这样就能达到理论的最大效率。<br>同样下表根据Little 法则给出了需要多少线程束来最小化内存读取延迟，不过这里有个单位换算过程，机器的性能指标内存读取速度给出的是GB/s 的单位，而我们需要的是每个时钟周期读取字节数，所以要用这个速度除以频率，例如C 2070 的内存带宽是144 GB/s 化成时钟周期： $\frac{144GB/s}{1.566GHz}=92 B/t$ ,这样就能得到单位时间周期的内存带宽了。<br>得出下表的数据<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_4.png" alt=""></p><p>需要说明的是这个速度不是单个SM的而是整个GPU设备的，以内们用的内存带宽是GPU设备的而不是针对一个SM的。<br>Fermi 需要并行的读取74的数据才能让GPU带宽满载，如果每个线程读取4个字节，我们大约需要18500个线程，大约579个线程束才能达到这个峰值。<br>所以，延迟的隐藏取决于活动的线程束的数量，数量越多，隐藏的越好，但是线程束的数量又受到上面的说的资源影响。所以这里就需要寻找最优的执行配置来达到最优的延迟隐藏。</p><p>那么我们怎么样确定一个线程束的下界呢，使得当高于这个数字时SM的延迟能充分的隐藏，其实这个公式很简单，也很好理解，就是SM的计算核心数乘以单条指令的延迟，<br>比如32个单精度浮点计算器，每次计算延迟20个时钟周期，那么我需要最少 32x20 =640 个线程使设备处于忙碌状态。</p><h2 id="占用率"><a href="#占用率" class="headerlink" title="占用率"></a>占用率</h2><p>占用率是一个SM种活跃的线程束的数量，占SM最大支持线程束数量的比，<br>我们前面写的程序7_deviceInformation 中添加几个成员的查询就可以帮我们找到这个值：<br>完整代码：<a href="https://github.com/Tony-Tan/CUDA_Freshman" target="_blank" rel="noopener">https://github.com/Tony-Tan/CUDA_Freshman</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略了上半部分</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"----------------------------------------------------------\n"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Number of multiprocessors:                      %d\n"</span>, deviceProp.multiProcessorCount);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total amount of constant memory:                %4.2f KB\n"</span>,</span><br><span class="line">deviceProp.totalConstMem/<span class="number">1024.0</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total amount of shared memory per block:        %4.2f KB\n"</span>,</span><br><span class="line"> deviceProp.sharedMemPerBlock/<span class="number">1024.0</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Total number of registers available per block:  %d\n"</span>,</span><br><span class="line">deviceProp.regsPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Warp size                                       %d\n"</span>, deviceProp.warpSize);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum number of threads per block:            %d\n"</span>, deviceProp.maxThreadsPerBlock);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum number of threads per multiprocessor:  %d\n"</span>,</span><br><span class="line">deviceProp.maxThreadsPerMultiProcessor);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Maximum number of warps per multiprocessor:     %d\n"</span>,</span><br><span class="line">deviceProp.maxThreadsPerMultiProcessor/<span class="number">32</span>);</span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br></pre></td></tr></table></figure><p>结果<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/devinf.png" alt=""></p><p>最大64个线程束每个SM。<br>CUDA工具包中提供一个叫做UCDA占用率计算器的电子表格，填上相关数据可以帮你自动计算网格参数：<br><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/excel.png" alt=""></p><p>上图是书上的截图，吐个槽，这些人居然写了个表格，为啥不写个程序？</p><p>上面我们已经明确内核使用寄存器的数量会影响SM内线程束的数量，nvcc的编译选项也有手动控制寄存器的使用。<br>也可以通过调整线程块内线程的多少来提高占用率，当然要合理不能太极端：</p><ul><li>小的线程块：每个线程块中线程太少，会在所有资源没用完就达到了线程束的最大要求</li><li>大的线程块：每个线程块中太多线程，会导致每个SM中每个线程可用的硬件资源较少。</li></ul><h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><p>并发程序对同步非常有用，比如pthread中的锁，openmp中的同步机制，这没做的主要目的是避免内存竞争<br>CUDA同步这里只讲两种：</p><ul><li>线程块内同步</li><li>系统级别</li></ul><p>块级别的就是同一个块内的线程会同时停止在某个设定的位置，用<br></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__syncthread();</span><br></pre></td></tr></table></figure><p></p><p>这个函数完成，这个函数只能同步同一个块内的线程，不能同步不同块内的线程，想要同步不同块内的线程，就只能让核函数执行完成，控制程序交换主机，这种方式来同步所有线程。</p><p>内存竞争是非常危险的，一定要非常小心，这里经常出错。</p><h2 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h2><p>可扩展性其实是相对于不同硬件的，当某个程序在设备1上执行的时候时间消耗是T当我们使用设备2时，其资源是设备1的两倍，我们希望得到T/2的运行速度，这种性质是CUDA驱动部分提供的特性，目前来说 Nvidia正在致力于这方面的优化，如下图：</p><p><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/CUDA-F-3-2-理解线程束执行的本质-P2/3_18.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天效率很高，主要是这个部分之前已经研究透彻了，第三章是Freshman阶段的最核心部分，需要大家多查资料，多思考，多练习，待续。。。</p><p>原文地址1：<a href="https://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2">https://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2</a>转载请标明出处</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>谭升</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2/" title="\[CUDA 基础\]3.2 理解线程束执行的本质(Part II)">http://www.face2ai.com/CUDA-F-3-2-理解线程束执行的本质-P2/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Math-Probability-3-7-Multivariate-Distributions-P2/" rel="next" title="\[概率论\]3-7:多变量分布(Multivariate Distributions Part II）"><i class="fa fa-chevron-left"></i> \[概率论\]3-7:多变量分布(Multivariate Distributions Part II）</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/Math-Probability-3-8-Fuctions-of-a-Random-Variable/" rel="prev" title="\[概率论\]3-8:随机变量函数(Functions of a Random Variable)">\[概率论\]3-8:随机变量函数(Functions of a Random Variable) <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/weixingongzhonghao.jpg" alt="wechat"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-"></i> </span><span class="author" itemprop="copyrightHolder">谭升</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>