<!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=6.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=6.4.0"><link rel="mask-icon" href="/images/logo.png?v=6.4.0" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"6.4.0",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="Abstract: 本文介绍《推测术》中最精华的第四部分，提出历史性结论——伯努利大数定律Keywords: 大数定律，伯努利大数定律，《推测术》，强大数律，弱大数律，切比雪夫不等式"><meta name="keywords" content="大数定律,伯努利大数定律,《推测术》,强大数律,弱大数律,切比雪夫不等式"><meta property="og:type" content="article"><meta property="og:title" content="【数理统计学简史】1.7 伯努利大数定律"><meta property="og:url" content="http://www.face2ai.com/Math-Statistics-1-7-Bernouli-Law-of-Large-Numbers/index.html"><meta property="og:site_name" content="谭升的博客"><meta property="og:description" content="Abstract: 本文介绍《推测术》中最精华的第四部分，提出历史性结论——伯努利大数定律Keywords: 大数定律，伯努利大数定律，《推测术》，强大数律，弱大数律，切比雪夫不等式"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2018-07-12T15:48:10.651Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【数理统计学简史】1.7 伯努利大数定律"><meta name="twitter:description" content="Abstract: 本文介绍《推测术》中最精华的第四部分，提出历史性结论——伯努利大数定律Keywords: 大数定律，伯努利大数定律，《推测术》，强大数律，弱大数律，切比雪夫不等式"><link rel="canonical" href="http://www.face2ai.com/Math-Statistics-1-7-Bernouli-Law-of-Large-Numbers/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>【数理统计学简史】1.7 伯努利大数定律 | 谭升的博客</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105335860-3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-105335860-3")</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">谭升的博客</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Machine Learning & Computer Vision</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-首页"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-数学"><a href="/categories/Mathematic/" rel="section">数学</a></li><li class="menu-item menu-item-···-集合论"><a href="/categories/Mathematic/Set-Theory/" rel="section">··· 集合论</a></li><li class="menu-item menu-item-···-线性代数基础"><a href="/categories/Mathematic/Linear-Algebra/" rel="section">··· 线性代数基础</a></li><li class="menu-item menu-item-···-概率论基础"><a href="/categories/Mathematic/Probability/" rel="section">··· 概率论基础</a></li><li class="menu-item menu-item-···-数理统计学"><a href="/categories/Mathematic/Statistics/" rel="section">··· 数理统计学</a></li><li class="menu-item menu-item-···-数值分析"><a href="/categories/Mathematic/Numerical-Analysis/" rel="section">··· 数值分析</a></li><li class="menu-item menu-item-机器学习算法"><a href="/categories/Machine-Learning/" rel="section">机器学习算法</a></li><li class="menu-item menu-item-强化学习"><a href="/categories/Reinforcement-Learning/" rel="section">强化学习</a></li><li class="menu-item menu-item-深度学习算法"><a href="/categories/Deep-Learning/" rel="section">深度学习算法</a></li><li class="menu-item menu-item-数字图像处理"><a href="/categories/DIP/" rel="section">数字图像处理</a></li><li class="menu-item menu-item-30天自制操作系统"><a href="/categories/30天自制操作系统/" rel="section">30天自制操作系统</a></li><li class="menu-item menu-item-cuda"><a href="/categories/CUDA/" rel="section">CUDA</a></li><li class="menu-item menu-item-网络爬虫"><a href="/categories/Crawler/" rel="section">网络爬虫</a></li><li class="menu-item menu-item-乱七八糟"><a href="/categories/Other/" rel="section">乱七八糟</a></li></ul></nav><img src="https://tony4ai-1251394096.cos.ap-hongkong.myqcloud.com/blog_images/Wechat.jpeg" alt="wechat"></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="9135658886" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.face2ai.com/Math-Statistics-1-7-Bernouli-Law-of-Large-Numbers/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Tony"><meta itemprop="description" content="关注机器学习，深度学习，机器视觉，模式识别"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="谭升的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">【数理统计学简史】1.7 伯努利大数定律</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-04-30 17:16:04" itemprop="dateCreated datePublished" datetime="2018-04-30T17:16:04+08:00">2018-04-30</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/" itemprop="url" rel="index"><span itemprop="name">Mathematic</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Mathematic/Statistics/" itemprop="url" rel="index"><span itemprop="name">Statistics</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> 阅读次数： <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Abstract:</strong> 本文介绍《推测术》中最精华的第四部分，提出历史性结论——伯努利大数定律<br><strong>Keywords:</strong> 大数定律，伯努利大数定律，《推测术》，强大数律，弱大数律，切比雪夫不等式</p><a id="more"></a><h2 id="伯努利大数定律"><a href="#伯努利大数定律" class="headerlink" title="伯努利大数定律"></a>伯努利大数定律</h2><p>现在我们就要详细说说《推测术》的第四部分，包含了我们现在称之为伯努利大数定律的部分。回到前面我们从箱子里面拿球的试验设计：箱子中有a个白球，b个红球， $p=\frac{a}{a+b}$ 有放回地从箱子中拿球 $N$ 次，记录拿到把球的次数为 $X$ 用 $\frac{X}{N}$ 去估计 $p$ ,这个看似简单且顺理成章的想法是现今数理统计学中最重要的基本方法之一。此处暗含了一个最重要的条件就是每次拿球，每个球被拿到的概率相等。<br>其实拿球这事不难，每次拿球每个球有相同概率被拿到这件事非常有难度，也就是产生概率相等的随机数的过程是非常难控制的，换句话说，你怎么就能保证你的每次操作对于所有球都是一视同仁的呢？从另一个角度来看，彩票抽奖的那个装置也是非常复杂的，才能保证近似等概率。统计学家在平时需要随机数的时候，他们回去用一个叫做随机数表的东西，是一本很厚的记录随机数（0到9），用所谓“充分随机”的方法产生的，但是必须注意，到目前位为止，人们并无一种可操作的方法实现绝对的等可能，所谓随机数也常被人称为 “伪随机数”。<br>伯努利想要证明：用 $\frac{X}{N}$ 估计 $p$ 可以达到事实上的确定性——他称之为道德确定性（上一篇说到的），其数学描述：任意给定两个数， $\varepsilon&gt;0$ 和 $\eta&gt;0$ ,总可以取足够大的抽取次数 $N$ 使得 ${|\frac{X}{N}-p|&gt;\varepsilon}$ 的概率不超过 $\eta$ ，这个说法和极限的描述很类似，从字面上将就是 $p$ 和 $\frac{X}{N}$ 可以任意的接近，方法是通过增大抽取次数 $N$<br>显然这段话是我们用现代数学语言描述的，当年没有这么套路的说法，原著上伯努利用 $\frac{1}{a+b}$ 表示的 $\varepsilon$ ，也就是取样的结果 $\frac{X}{N}$ 和理论 $p$ 之间的绝对差距，小于 $\frac{1}{a+b}$ 这个换成 $\varepsilon$ 其实很容易，因为对于任意小的 $\varepsilon$ 我们可以通过调整箱子内球的数量来得到更小的的 $\frac{1}{a+b}$ 我们把 $a,b$ 扩大同样的倍数，比如 $ra,rb$ 这样整个实验是不变的 $p=\frac{ra}{ra + rb}$ ，但是 $\frac{1}{a+b}\to \frac{r}{ra+rb}$ 其次原著中要证明的是对于任意 $c&gt;0$ ，只需要抽取次数 $N$ 足够大，可以得到：<br>$$<br>P{|\frac{X}{N}-p|\leq \varepsilon}&gt;cP(|\frac{X}{N}-p|&gt;\varepsilon)\tag{8}<br>$$<br>和我们前面用现代语言描述的也是一致的，因为：<br>$$<br>\begin{aligned}<br>cP(|\frac{X}{N}-p|&gt;\varepsilon)&amp;&lt;P{|\frac{X}{N}-p|\leq \varepsilon}\\<br>&amp;&lt;\frac{1}{c+1}<br>\end{aligned}\tag{9}<br>$$</p><p>是不是看不明白 $c+1$ 哪里来的？<br>$$<br>P{|\frac{X}{N}-p|\leq \varepsilon}+P{|\frac{X}{N}-p|&gt; \varepsilon}=1\\<br>P{|\frac{X}{N}-p|\leq \varepsilon}&gt;cP(|\frac{X}{N}-p|&gt;\varepsilon)\\<br>$$<br>等式带入不等式就能得到结论了。</p><p>这样如果取 $c$ 充分大可使它小于 $\eta$ 。另外要指出的是：伯努利使用的这个箱子模型使被估计的 $p$ 值只能取有理数，所以这对普遍性是个问题，但是其证明对任意 $p$ 都是有效的，所以这个试验的漏洞也就可以被忽略了。<br>伯努利当时比较高明的一点是他描述这个问题的时候用了(8)式，如果用他这个描述，我们用现在的的描述方法是——当N充分大，$\frac{X}{N}$ 和 $p$ 可以任意接近:<br>$$<br>lim_{N\to \infty}\frac{X}{N}=p\tag{10}<br>$$<br>上面这种现代写法在当时看有些问题的，因为我们不能排除从箱子里拿球的时候每次都拿到白球，这时候 $\frac{X}{N}=1$ 不能收敛到一个小于1的 $p$ 所以这种提法在伯努利时代可能真的解决不了，当时还没有抽象到这个层次，毕竟当时微积分也才刚刚出现。<br>上面这个结论是对的，<font color="006600">1909年</font>波莱尔证明了其正确性，证明难度比伯努利的描述难很多。波莱尔的结论比伯努利强，所以叫做强大数定律，伯努利的则称为弱大数定律。<br>接下来是详细的证明过程，这里先不写详细的，只写思路，因为虽然是伯努利给出的证明，但是以我的智力只能看懂一部分，为了不打消大家的积极性，我决定忽略详细过程，只介绍一点基础的，有兴趣的同学可以参考《数理统计学简史》第24页。<br>伯努利用的是直接估计法：</p><ul><li>首先设一个 $A_0=P(N_p&lt;X&lt;N_p+N_{\varepsilon})$</li><li>然后写一个递推关系 $A_k=P(N_p+kN_{\varepsilon}&lt;X&lt;N_p+(k+1)N_{\varepsilon}),k=1,2,\dots$</li><li>这样只需要证明 $N$ 充分大的时候 $A_0\geq c(A_1+A_2+\dots)$</li><li>这样就可以得到 $X&gt; N_p$ 的一边，同理可以得到另一边。</li></ul><p>这是大概的证明过程，可以得到(8)中的结论。<br>顺带的指出，可以把伯努利的结论(9)引申一点，如果我们知道箱子中球的总数也就是 $a+b$ 的值，或者知道 $a+b$ 不超过某个值 $M$ ，则可以把(9)式(书上写的是(3)式，应该是笔误)改进成——找到一个 $p$ 的估计 $\hat{p}(X)$ 而不是 $\frac{X}{N}$ ，当 $N$ 充分大时有：<br>$$<br>P(\hat{p}(X)\neq p)&lt;(c+1)^{-1}<br>$$<br>但是如果 $a+b$ 的值没有范围，这个结论就不成立了，证明也在书上，更加复杂，这里也不写了，想知道的同学可以参考数理统计学简史》第25页。<br>其实我们可以想想，我们讲了半天，都在说 $N$ 在达到一定大小的时候，比例会接近某个概率，我们和伯努利都有一个问题就是，N到底要多大，是否有下界，在指定的精度 $\varepsilon$ 下得出这个下界。并且可靠度不能超低于 $1-(c+1)^{-1}$ 他证明了以下的结果，定义：<br>$$<br>m_1=\text{ 不小于 } \frac{log[c(b-1)]}{log(a+1)-log(a)}\text{ 的最小整数 } \\<br>m_2=\text{ 不小于 } \frac{log[c(a-1)]}{log(b+1)-log(b)}\text{ 的最小整数 } \\<br>N_1=\frac{m_1(a+b)+b(a+b)(m_1-1)}{a+1}\\<br>N_2=\frac{m_2(a+b)+b(a+b)(m_2-1)}{b+1}<br>$$<br>则取 $max{N_1,N_2}$ 能满足 (9) 式，伯努利给了若干数字例子，比如：$a=30,b=20(p=\frac{3}{5}),\varepsilon=\frac{1}{50},c=1000$ 使用上面的结论， $N$ 至少是 25550 ,我们在<a href="https://face2ai.com/Math-Probability-6-2-The-Law-of-Large-Numbers/" target="_blank" rel="noopener">基础概率论中介绍过切比雪夫不等式</a>，也是给出N的参考值的，但是在同精度下，伯努利给出的N的大小比切比雪夫不等式给出的N小20多倍，但是这个25550这个数还是太大，当时美国一个中等城市人口也就几千人，所以学者斯蒂格勒认为，伯努利之所以长期没发布结果，是觉得这个数太大，他想找到更小的。<br>但是现在我们已经不关注这些地方了，大家都公认，由伯努利工作发端的大数定律已经成为整个数理统计学的基础，人们也对伯努利工作的哲学意义给予极高的评价，斯蒂格勒指出，伯努利证明了数学家不仅可以后验的认识世界，还可以用数学取菇凉他们的知识的限度。伯努利在结束《推测术》时就其结果的意义做出如下表述：</p><blockquote><p>如果我们能把一切事物永恒的观察下去，则我们终将发现：世间的一切事物都受到因果律的支配，而我们也注定会在种种及其纷繁杂乱的事项中认识到某种必然。</p></blockquote><p>怎么样，像哲学吧，其实是数学家说的！哈哈。<br>然后就是关于 $N$ 到底还能不能小一点。</p><ol><li><font color="006600">1713年</font> 伯努利的侄儿，尼古拉斯·伯努利在给有人的信件中报告了一个他的结果，比伯努利的结果有所改善</li><li><font color="006600">1733年</font> 狄莫弗发展了用正态分布逼近二项分布的方法，这是一个意义深远的改进，我们在第二章中学习，将N继续缩小到越 6600，这已经没什么改进余地了，但还是不小。</li></ol><p>显然大自然不想让我们轻易的看清他的面貌，这个例子也告诉我们，在平时的书刊杂志小软文中根据一个小样本得到的某种特征的比例，作为大群体中该特征的估值，其准确度和可靠性，通常还没有没什么统计学知识的公众所认为的（主观概率）准确。所以可以对他们给出的结论，看看就好，别当真。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本问是第一章最后一篇，大数定律影响了我们整个学科，对后世影响深远。<br>今天是高斯的诞辰，我辈继续努力吧。</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>Tony</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://www.face2ai.com/Math-Statistics-1-7-Bernouli-Law-of-Large-Numbers/" title="【数理统计学简史】1.7 伯努利大数定律">http://www.face2ai.com/Math-Statistics-1-7-Bernouli-Law-of-Large-Numbers/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/CUDA-F-4-1-内存模型概述/" rel="next" title="【CUDA 基础】4.1 内存模型概述"><i class="fa fa-chevron-left"></i> 【CUDA 基础】4.1 内存模型概述</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/Math-Statistics-2-0-De-Moivre-Binomial-Distribution/" rel="prev" title="【数理统计学简史】2.0 狄莫弗的二项概率逼近">【数理统计学简史】2.0 狄莫弗的二项概率逼近 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1194454329688573" data-ad-slot="2491973880" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Tony"><p class="site-author-name" itemprop="name">Tony</p><p class="site-description motion-element" itemprop="description">关注机器学习，深度学习，机器视觉，模式识别</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">257</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">17</span> <span class="site-state-item-name">分类</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tony-tan" target="_blank" title="GitHub" rel="external nofollow"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tony.face2ai@gmail.com" target="_blank" title="E-Mail" rel="external nofollow"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://twitter.com/Tony_Face2AI" target="_blank" title="Twitter" rel="external nofollow"><i class="fa fa-fw fa-twitter"></i>Twitter</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#伯努利大数定律"><span class="nav-number">1.</span> <span class="nav-text">伯努利大数定律</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">2.</span> <span class="nav-text">总结</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-"></i> </span><span class="author" itemprop="copyrightHolder">Tony</span></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv" title="总访客量"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv" title="总访问量"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/affix.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>